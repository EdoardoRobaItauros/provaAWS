{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.7/site-packages (0.5.2)\n",
      "Requirement already satisfied: aiobotocore>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from s3fs) (1.2.2)\n",
      "Requirement already satisfied: fsspec>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from s3fs) (0.8.7)\n",
      "Requirement already satisfied: aioitertools>=0.5.1 in /opt/conda/lib/python3.7/site-packages (from aiobotocore>=1.0.1->s3fs) (0.7.1)\n",
      "Requirement already satisfied: aiohttp>=3.3.1 in /opt/conda/lib/python3.7/site-packages (from aiobotocore>=1.0.1->s3fs) (3.7.4.post0)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in /opt/conda/lib/python3.7/site-packages (from aiobotocore>=1.0.1->s3fs) (1.11.2)\n",
      "Collecting botocore<1.19.53,>=1.19.52\n",
      "  Using cached botocore-1.19.52-py2.py3-none-any.whl (7.2 MB)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from fsspec>=0.8.0->s3fs) (1.5.0)\n",
      "Requirement already satisfied: typing_extensions>=3.7 in /opt/conda/lib/python3.7/site-packages (from aioitertools>=0.5.1->aiobotocore>=1.0.1->s3fs) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<5.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs) (3.0.4)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs) (3.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs) (5.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs) (1.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs) (19.3.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.19.53,>=1.19.52->aiobotocore>=1.0.1->s3fs) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4; python_version != \"3.4\" in /opt/conda/lib/python3.7/site-packages (from botocore<1.19.53,>=1.19.52->aiobotocore>=1.0.1->s3fs) (1.25.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.19.53,>=1.19.52->aiobotocore>=1.0.1->s3fs) (2.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->fsspec>=0.8.0->s3fs) (2.2.0)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs) (2.8)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.19.53,>=1.19.52->aiobotocore>=1.0.1->s3fs) (1.14.0)\n",
      "\u001b[31mERROR: boto3 1.17.34 has requirement botocore<1.21.0,>=1.20.34, but you'll have botocore 1.19.52 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: awscli 1.19.34 has requirement botocore==1.20.34, but you'll have botocore 1.19.52 which is incompatible.\u001b[0m\n",
      "Installing collected packages: botocore\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.20.34\n",
      "    Uninstalling botocore-1.20.34:\n",
      "      Successfully uninstalled botocore-1.20.34\n",
      "Successfully installed botocore-1.19.52\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main_aggregazioni.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main_aggregazioni.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "# from scipy import stats\n",
    "from datetime import datetime\n",
    "import calendar as c\n",
    "\n",
    "def lettura_temp_norm(file_t_norm):\n",
    "#     df = pd.read_csv(file_t_norm)#,encoding='utf-16')\n",
    "    df = costruzione_file_da_mensile(file_t_norm,inizio,fine)\n",
    "#     df.rename(columns={'TIME - Date':'date','Codice Provincia':'provincia','Temperature Min':'temp_min','Temperature Max':'temp_max'},inplace=True)\n",
    "    df = df[['DATA','PROVINCIA','TEMPERATURA_MAX','TEMPERATURA_MIN']]\n",
    "    df.rename(columns={'DATA':'date','PROVINCIA':'provincia','TEMPERATURA_MIN':'temp_min','TEMPERATURA_MAX':'temp_max'},inplace=True)\n",
    "    df = df[~df['provincia'].isnull()]\n",
    "    df['date'] = pd.to_datetime(df['date'],format='%d/%m/%Y')\n",
    "    df['daymonth'] = (df.date.dt.day).astype('str').str.pad(2, side='left', fillchar='0') + (df.date.dt.month).astype('str').str.pad(2, side='left', fillchar='0')\n",
    "    df['T_mean'] = df[['temp_min', 'temp_max']].mean(axis=1)\n",
    "    df.drop('Desc_Provincia',axis=1,inplace=True)\n",
    "#     df.info()\n",
    "\n",
    "    df = df.assign(\n",
    "        dayofyear=lambda x: (x.date).dt.dayofyear, # + pd.DateOffset(days=92)\n",
    "        year=lambda x: (x.date).dt.year, #  + pd.DateOffset(days=92)\n",
    "    )\n",
    "#     print(df)\n",
    "    df['dayofyear'] = df.apply(lambda x: x['dayofyear']+1 if (c.isleap(x['year'])==False and x['date'].month>=3 and x['date'].month<=12) else x['dayofyear'],axis=1)\n",
    "    df['monthyear'] = (df.date.dt.month).astype('str').str.pad(2, side='left', fillchar='0')+(df.year).astype('str')\n",
    "    return df\n",
    "\n",
    "def lettura_temp_norm_curve_min_max(nome_file):\n",
    "    df = pd.read_csv(nome_file)#,encoding='utf-16')\n",
    "#     print(df)\n",
    "#     df['date'] = pd.to_datetime(df['date'],format='%Y-%m-%d')\n",
    "\n",
    "#GIUSTO\n",
    "    df['monthday'] = (df.mese).astype('str').str.pad(2, side='left', fillchar='0') +'-'+ (df.giorno).astype('str').str.pad(2, side='left', fillchar='0')\n",
    "    df['date'] = \"2020-\" + df['monthday']\n",
    "    df['date'] = pd.to_datetime(df['date'],format='%Y-%m-%d')\n",
    "\n",
    "#DA TOGLIERE\n",
    "#     df['mese'] = df.date.dt.month\n",
    "#     df['giorno'] = df.date.dt.day\n",
    "    \n",
    "    col = [x for x in df.columns if 'T_' in x][0]\n",
    "    if 'provincia' in df.columns:\n",
    "        codice = 'provincia'\n",
    "    else:\n",
    "        codice = 'codice_oss'\n",
    "    df = df.assign(\n",
    "      dayofyear=lambda x: (x.date).dt.dayofyear, # + pd.DateOffset(days=92)\n",
    "      year=lambda x: (x.date).dt.year, # + pd.DateOffset(days=92)\n",
    "    )\n",
    "    df['dayofyear'] = df.apply(lambda x: x['dayofyear']+1 if (c.isleap(x['year'])==False and x['date'].month>=3 and x['date'].month<=12) else x['dayofyear'],axis=1)\n",
    "    df.drop('date',axis=1,inplace=True)\n",
    "\n",
    "    return df, col, codice\n",
    "\n",
    "def lettura_osservatorio(file_oss):\n",
    "    df_oss = pd.read_csv(file_oss)\n",
    "    df_oss.rename(columns={'Cd Oss':'codice_oss','T Oss':'T_oss','Data':'date'},inplace=True)\n",
    "#     df_oss = df_oss[df_oss['codice_oss']==11]\n",
    "    df_oss['T_oss'] = df_oss.apply(lambda x: 18 if x['T_oss']==0 else 18-x['T_oss'],axis=1)\n",
    "    df_oss['date'] = df_oss['date'].astype('str')\n",
    "    df_oss['date'] = pd.to_datetime(df_oss['date'],format='%d/%m/%Y', exact=False)\n",
    "    df_oss['daymonth'] = (df_oss.date.dt.day).astype('str').str.pad(2, side='left', fillchar='0') + (df_oss.date.dt.month).astype('str').str.pad(2, side='left', fillchar='0')\n",
    "    df_oss = df_oss.assign(\n",
    "        dayofyear=lambda x: (x.date).dt.dayofyear, # + pd.DateOffset(days=92)\n",
    "        year=lambda x: (x.date).dt.year, # + pd.DateOffset(days=92)\n",
    "    )\n",
    "    df_oss['dayofyear'] = df_oss.apply(lambda x: x['dayofyear']+1 if (c.isleap(x['year'])==False and x['date'].month>=3 and x['date'].month<=12) else x['dayofyear'],axis=1)\n",
    "    df_oss.drop('Oss',axis=1,inplace=True)\n",
    "    df_oss['monthyear'] = (df_oss.date.dt.month).astype('str').str.pad(2, side='left', fillchar='0')+(df_oss.year).astype('str')\n",
    "    return df_oss\n",
    "\n",
    "def compute_yhat_prov(file_t_norm):\n",
    "\n",
    "#     Calcolo temperature normali giornaliere    \n",
    "    df = lettura_temp_norm(file_t_norm)\n",
    "    df.rename(columns={'temp_max':'T_max_mean','temp_min':'T_min_mean','T_mean':'T_mean_m'},inplace=True)\n",
    "    \n",
    "    temp_norm = df.groupby(['dayofyear', 'provincia'])[['T_min_mean', 'T_max_mean','T_mean_m']].mean().unstack().reindex(range(367)).interpolate(method='linear').stack() #,'T_mean'\n",
    "    province = temp_norm.reset_index(['provincia']).provincia.unique()\n",
    "    finale = pd.DataFrame()\n",
    "\n",
    "#     Fit armoniche di sesto grado per curve T_min, T_max e T_mean\n",
    "    for p in province:\n",
    "        temp_p = temp_norm.query('provincia == {}'.format(p)).reset_index(['provincia'])#.assign(std_mean=lambda x: x['std'], iv_l=lambda x: (x['mean'] - 2*x['std'].rolling(window=15, center=True).mean()), iv_h=lambda x: (x['mean'] + 2*x['std'].rolling(window=15, center=True).mean()))\n",
    "\n",
    "        y_min = temp_p['T_min_mean'].values.ravel()\n",
    "        y_max = temp_p['T_max_mean'].values.ravel()\n",
    "        y_mean = temp_p['T_mean_m'].values.ravel()\n",
    "\n",
    "        x = temp_p.index\n",
    "        \n",
    "        yhat_min = fit_harmonics(y_min, 6)\n",
    "        yhat_max = fit_harmonics(y_max, 6)\n",
    "        yhat_mean = fit_harmonics(y_mean, 6)\n",
    "\n",
    "        temp_p['yhat_min'] = yhat_min\n",
    "        temp_p['yhat_max'] = yhat_max\n",
    "        temp_p['yhat_mean'] = yhat_mean\n",
    "\n",
    "        finale = finale.append(temp_p)\n",
    "\n",
    "    return finale.reset_index()\n",
    "\n",
    "def fit_harmonics(y, n_harmonics):\n",
    "    n = y.shape[0]\n",
    "    X = np.matrix([*[[np.sin(i*k/n*2*np.pi) for i in range(n)] for k in range(n_harmonics)], *[[np.cos(i*k/n*2*np.pi) for i in range(n)] for k in range(n_harmonics)]]).T\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    ols_model = sm.OLS(y, X).fit()\n",
    "    yhat = ols_model.predict(X)\n",
    "    \n",
    "    return yhat\n",
    "\n",
    "def aggregazione_serie_storiche_curve_min_max(nome_file,df_pesi,col_pesi_merge):\n",
    "#     DA RICONTROLLARE COL FILE GIUSTO.\n",
    "    \n",
    "    df, col, codice = lettura_temp_norm_curve_min_max(nome_file)\n",
    "    #df.drop('date',axis=1,inplace=True)\n",
    "    print(\"Lettura file di temperature \"+col+\" per \"+codice+\".\")\n",
    "    \n",
    "    print(\"Numero di \"+codice+\" presenti: \"+str(df[codice].nunique()))\n",
    "    \n",
    "#     if col_pesi_merge==['mese','giorno']:\n",
    "#         df_pesi.drop('date',axis=1,inplace=True)\n",
    "    \n",
    "    print(\"Procedura di ripartizione per peso avviata.\")\n",
    "    df_pesi = df.merge(df_pesi,on=col_pesi_merge+[codice],how='left')\n",
    "    df_pesi['sum_pesi_gg'] = df_pesi.groupby(col_pesi_merge)['peso'].transform('sum')\n",
    "    df_pesi[col+'_pesato'] = df_pesi[col]*df_pesi['peso']\n",
    "\n",
    "    df_pesi[col + '_pesato'] = df_pesi.groupby(col_pesi_merge)[col + '_pesato'].transform('sum')\n",
    "\n",
    "    df_pesi[col+'_pesato'] = df_pesi[col+'_pesato']/df_pesi['sum_pesi_gg']\n",
    "    df_pesi = df_pesi[['date'] + col_pesi_merge+[col+'_pesato','sum_pesi_gg']]\n",
    "    return df_pesi, col\n",
    "\n",
    "def aggregazione_serie_storiche_norm_yhat(df,df_pesi,col_pesi_merge):\n",
    "#     DA RICONTROLLARE COL FILE GIUSTO.\n",
    "    print(\"Lettura file curva normale giornaliera da aggregare per provincia.\")\n",
    "    df = pd.read_csv(df)\n",
    "    \n",
    "    print(\"Numero province presenti: \",df.provincia.nunique())\n",
    "\n",
    "    df = df[['provincia','yhat_mean']+col_pesi_merge]\n",
    "    # df è il file di temperature max e min\n",
    "    df_pesi = df.merge(df_pesi,on=col_pesi_merge+['provincia'],how='left')\n",
    "\n",
    "    df_pesi['yhat_pesato'] = df_pesi['yhat_mean']*df_pesi['peso']\n",
    "    \n",
    "    df_pesi_mean_gg = df_pesi[['date','yhat_pesato']].groupby('date').sum().reset_index()\n",
    "\n",
    "    df_pesi_mean_gg['mese'] = (df_pesi_mean_gg.date.dt.month).astype('int')\n",
    "    df_pesi_mean_gg['giorno'] = (df_pesi_mean_gg.date.dt.day).astype('int')\n",
    "\n",
    "    df_pesi_mean = df_pesi_mean_gg.copy()#[['daymonth',col+'_pesato']].groupby('daymonth').mean().reset_index()\n",
    "    df_pesi_mean = df_pesi_mean.merge(df_pesi[col_pesi_merge+['sum_pesi_gg']],on=col_pesi_merge,how='left')\n",
    "    df_pesi_mean['yhat_pesato'] = df_pesi_mean['yhat_pesato']/df_pesi_mean['sum_pesi_gg']\n",
    "    df_pesi_mean = df_pesi_mean[['date','yhat_pesato','sum_pesi_gg']]\n",
    "    df_pesi_mean.drop_duplicates(subset=['date'],inplace=True)\n",
    "    return df_pesi_mean\n",
    "\n",
    "\n",
    "def aggregazione_serie_storiche_oss_yhat(df,df_pesi,col_pesi_merge):\n",
    "#     DA RICONTROLLARE COL FILE GIUSTO.\n",
    "    print(\"Lettura file curva normale giornaliera da aggregare per osservatorio.\")\n",
    "    df = pd.read_csv(df)\n",
    "    print(\"Numero osservatori presenti: \",df.codice_oss.nunique())\n",
    "\n",
    "#     df['date_prov'] = '2020-'+df['mese'].astype('str').str.pad(2,'left','0')+'-'+df['giorno'].astype('str').str.pad(2,'left','0')\n",
    "#     df.drop(['mese','giorno'],axis=1,inplace=True)\n",
    "#     df['date_prov'] = pd.to_datetime(df['date_prov'],format='%Y-%m-%d')\n",
    "#     df = df.assign(\n",
    "#       dayofyear=lambda x: (x.date_prov).dt.dayofyear,\n",
    "#     )\n",
    "\n",
    "    df = df[['codice_oss','yhat']+col_pesi_merge]\n",
    "    to_merge = df[col_pesi_merge].copy()\n",
    "\n",
    "    df_pesi = df.merge(df_pesi,on=col_pesi_merge+['codice_oss'],how='left')\n",
    "    df_pesi['yhat_pesato'] = df_pesi['yhat']*df_pesi['peso']\n",
    "    df_pesi_mean_gg = df_pesi[col_pesi_merge+['yhat_pesato','date']].groupby(col_pesi_merge).sum().reset_index()\n",
    "    df_pesi_mean_gg = df_pesi_mean_gg.merge(to_merge,on=col_pesi_merge,how='left')\n",
    "    #df_pesi_mean_gg['monthday'] = (df_pesi_mean_gg['date_prov'].dt.month).astype('str').str.pad(2, side='left', fillchar='0')+'-'+(df_pesi_mean_gg['date_prov'].dt.day).astype('str').str.pad(2, side='left', fillchar='0')\n",
    "\n",
    "    df_pesi_mean = df_pesi_mean_gg.copy()#[['daymonth',col+'_pesato']].groupby('daymonth').mean().reset_index()\n",
    "    df_pesi_mean = df_pesi_mean.merge(df_pesi[col_pesi_merge+['sum_pesi_gg','date']],on=col_pesi_merge,how='left')\n",
    "    df_pesi_mean['yhat_pesato'] = df_pesi_mean['yhat_pesato']/df_pesi_mean['sum_pesi_gg']\n",
    "    df_pesi_mean = df_pesi_mean[['date','mese','giorno','yhat_pesato','sum_pesi_gg']]\n",
    "    df_pesi_mean.drop_duplicates(subset=['mese','giorno'],inplace=True)\n",
    "#     df.drop('date_prov',axis=1,inplace=True)\n",
    "    \n",
    "    return df_pesi_mean\n",
    "    \n",
    "\n",
    "def main_aggregazioni(file_input,pesi,path_to_output):\n",
    "    print('Inizio funzione aggregazione')\n",
    "    print('\\n')\n",
    "    \n",
    "    my_bucket = 'zus-prod-s3'\n",
    "    \n",
    "    #idrun = '_'.join(file_input.split('/')[-2].split('_')[0:2]) + '_' + str(datetime.now())[0:-7].replace('-','').replace(' ','').replace(':','')\n",
    "    \n",
    "    df_pesi = pd.read_csv('s3://'+ my_bucket +'/'+pesi)\n",
    "    if 'consumo_termico' in df_pesi.columns:\n",
    "        df_pesi.rename(columns={'consumo_termico':'peso','osservatorio':'codice_oss'},inplace=True)\n",
    "        prv = pd.DataFrame()\n",
    "        prv['dayofyear'] = range(1,367)\n",
    "        prv['date'] = pd.date_range('2020-01-01','2020-12-31').astype('str')#.str.slice(start=5)\n",
    "        prv['date'] = pd.to_datetime(prv['date'],format='%Y-%m-%d')\n",
    "        df_pesi = df_pesi.merge(prv,on='dayofyear',how='left')\n",
    "    else:\n",
    "        df_pesi['date'] = pd.to_datetime(df_pesi['date'],format='%d/%m/%Y') #'%Y-%m-%d') '%d/%m/%Y'\n",
    "\n",
    "    df_pesi['mese'] = (df_pesi.date.dt.month).astype('int')\n",
    "    df_pesi['giorno'] = (df_pesi.date.dt.day).astype('int')\n",
    "    \n",
    "    inizio_pesi = min(df_pesi['date']).strftime('%Y-%m-%d')\n",
    "    fine_pesi = max(df_pesi['date']).strftime('%Y-%m-%d')\n",
    "    idrun = inizio_pesi.replace('-','') + '_' + fine_pesi.replace('-','') + '_' + str(datetime.now())[0:-7].replace('-','').replace(' ','').replace(':','')\n",
    "\n",
    "    df = pd.read_csv('s3://'+ my_bucket +'/'+file_input)\n",
    "    list_nome_file = file_input.split('/')\n",
    "\n",
    "    if 'provincia' in df.columns:\n",
    "        \n",
    "        col_pesi_merge = ['mese','giorno']\n",
    "\n",
    "        if 'yhat_mean' in df.columns:\n",
    "            df_pesi['sum_pesi_gg'] = df_pesi.groupby(['date'])['peso'].transform('sum')\n",
    "            \n",
    "            print('Aggregazione serie storiche temperature normali fittate (yhat_norm * pesi)')\n",
    "            \n",
    "            agg_ita = aggregazione_serie_storiche_norm_yhat('s3://'+ my_bucket +'/'+file_input,df_pesi,col_pesi_merge)\n",
    "            file_csv = file_input.split('/')[-1]\n",
    "            if 'max' in file_csv: tipo_yhat='max'\n",
    "            elif 'min' in file_csv: tipo_yhat='min'\n",
    "            else: tipo_yhat='mean'\n",
    "            nome_output = 'agg_ita_norm_prov/'+idrun+'/agg_ita_norm_'+tipo_yhat+'_prov.csv'\n",
    "            \n",
    "            metadatati = pd.DataFrame(data={'MODELLO':['AGG_ITA_NORM_PROV']*3,'ID_RUN':['s3://'+ my_bucket +'/'+path_to_output+nome_output]*3,'NOME_PARAMETRO':['FILE_INPUT','PESI','PATH_TO_OUTPUT'],'VALORE_PARAMETRO':[file_input,pesi,path_to_output+'agg_ita_norm_prov/best/agg_ita_norm_'+tipo_yhat+'_prov.csv']})\n",
    "            metadatati.to_csv('s3://'+ my_bucket +'/metadati/sistema/temperatura_norm/zeus/metadati/agg_ita_norm_prov/'+idrun+'/metadati.csv',index=False)\n",
    "\n",
    "        else:\n",
    "            print('Aggregazione curve min_max periodo (curve * pesi)')\n",
    "            \n",
    "            agg_ita, col = aggregazione_serie_storiche_curve_min_max('s3://'+ my_bucket +'/'+file_input,df_pesi,col_pesi_merge)\n",
    "            agg_ita.drop_duplicates(subset=['mese','giorno',col + '_pesato'],inplace=True) \n",
    "#             name = file_input.split('/')[-1]\n",
    "#             name = file_input.replace('.csv','')\n",
    "#             name = name.split('_')[-4:]\n",
    "#             name = '_'.join(name)\n",
    "            \n",
    "            if 'T_min' in df.columns:\n",
    "                nome_output = 'agg_ita_min_periodo_prov/'+idrun+'/agg_ita_min_periodo_prov.csv'\n",
    "                metadatati = pd.DataFrame(data={'MODELLO':['AGG_ITA_MIN_PERIODO_PROV']*3,'ID_RUN':['s3://'+ my_bucket +'/'+path_to_output+nome_output]*3,'NOME_PARAMETRO':['FILE_INPUT','PESI','PATH_TO_OUTPUT'],'VALORE_PARAMETRO':[file_input,pesi,path_to_output+nome_output]})\n",
    "                metadatati.to_csv('s3://'+ my_bucket +'/metadati/sistema/temperatura_norm/zeus/metadati/agg_ita_min_periodo_prov/'+idrun+'/metadati.csv',index=False)\n",
    "            else:\n",
    "                nome_output = 'agg_ita_max_periodo_prov/'+idrun+'/agg_ita_max_periodo_prov.csv'\n",
    "                metadatati = pd.DataFrame(data={'MODELLO':['AGG_ITA_MAX_PERIODO_PROV']*3,'ID_RUN':['s3://'+ my_bucket +'/'+path_to_output+nome_output]*3,'NOME_PARAMETRO':['FILE_INPUT','PESI','PATH_TO_OUTPUT'],'VALORE_PARAMETRO':[file_input,pesi,path_to_output+nome_output]})\n",
    "                metadatati.to_csv('s3://'+ my_bucket +'/metadati/sistema/temperatura_norm/zeus/metadati/agg_ita_max_periodo_prov/'+idrun+'/metadati.csv',index=False)\n",
    "\n",
    "#         agg_ita['mese'] = agg_ita['date'].dt.month\n",
    "#         agg_ita['giorno'] = agg_ita['date'].dt.day\n",
    "#         print(\"prov: \",agg_ita)\n",
    "\n",
    "        agg_ita.to_csv('s3://'+ my_bucket +'/'+path_to_output+nome_output,index=False)\n",
    "    \n",
    "#         pesi_mean_norm.to_csv(path_output+'agg_ita/best/'+nome_output+'_T_mean_p.csv',index=False)\n",
    "#         pesi_yhat_norm.to_csv(path_output+'agg_ita/best/'+nome_output+'_yhat_p.csv',index=False)\n",
    "        #agg_ita.to_csv('prova_agg_prov.csv',index=False)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        col_pesi_merge = ['mese','giorno']#['dayofyear']\n",
    "        \n",
    "        if 'yhat' in df.columns:\n",
    "            df_pesi['sum_pesi_gg'] = df_pesi.groupby(['dayofyear'])['peso'].transform('sum')\n",
    "            df_pesi.drop('dayofyear',axis=1,inplace=True)\n",
    "\n",
    "            print('Aggregazione serie storiche temperature normali fittate (yhat_norm * pesi)')\n",
    "            agg_ita = aggregazione_serie_storiche_oss_yhat('s3://'+ my_bucket +'/'+file_input,df_pesi,col_pesi_merge)\n",
    "            file_csv = file_input.split('/')[-1]\n",
    "            if 'max' in file_csv: tipo_yhat='max'\n",
    "            elif 'min' in file_csv: tipo_yhat='min'\n",
    "            else: tipo_yhat='mean'\n",
    "            nome_output = 'agg_ita_norm_oss/'+idrun+'/agg_ita_norm_'+tipo_yhat+'_oss.csv'\n",
    "            \n",
    "            metadatati = pd.DataFrame(data={'MODELLO':['AGG_ITA_NORM_OSS']*3,'ID_RUN':['s3://'+ my_bucket +'/'+path_to_output+nome_output]*3,'NOME_PARAMETRO':['FILE_INPUT','PESI','PATH_TO_OUTPUT'],'VALORE_PARAMETRO':[file_input,pesi,path_to_output+'agg_ita_norm_oss/best/agg_ita_norm_'+tipo_yhat+'_oss.csv']})\n",
    "\n",
    "            metadatati.to_csv('s3://'+ my_bucket +'/metadati/sistema/temperatura_norm/zeus/metadati/agg_ita_norm_oss/'+idrun+'/metadati.csv',index=False)\n",
    "           \n",
    "        else:\n",
    "            print('Aggregazione curve min_max periodo (curve * pesi)')\n",
    "            df_pesi.drop('dayofyear',axis=1,inplace=True)\n",
    "\n",
    "            agg_ita, col = aggregazione_serie_storiche_curve_min_max('s3://'+ my_bucket +'/'+file_input,df_pesi,col_pesi_merge)\n",
    "            agg_ita.drop_duplicates(subset=['mese','giorno',col + '_pesato'],inplace=True)\n",
    "#             name = file_input.split('/')[-1]\n",
    "#             print(name)\n",
    "#             name = file_input.replace('.csv','')\n",
    "#             name = name.split('_')[-4:]\n",
    "#             name = '_'.join(name)\n",
    "            if 'min' in list_nome_file[-1]:\n",
    "                nome_output = 'agg_ita_min_periodo_oss/'+idrun+'/agg_ita_min_periodo_oss.csv'\n",
    "                metadatati = pd.DataFrame(data={'MODELLO':['AGG_ITA_MIN_PERIODO_PROV']*3,'ID_RUN':['s3://'+ my_bucket +'/'+path_to_output+nome_output]*3,'NOME_PARAMETRO':['FILE_INPUT','PESI','PATH_TO_OUTPUT'],'VALORE_PARAMETRO':[file_input,pesi,path_to_output+nome_output]})\n",
    "                metadatati.to_csv('s3://'+ my_bucket +'/metadati/sistema/temperatura_norm/zeus/metadati/agg_ita_min_periodo_oss/'+idrun+'/metadati.csv',index=False)\n",
    "            else:\n",
    "                nome_output = 'agg_ita_max_periodo_oss/'+idrun+'/agg_ita_max_periodo_oss.csv'\n",
    "                metadatati = pd.DataFrame(data={'MODELLO':['AGG_ITA_MIN_PERIODO_PROV']*3,'ID_RUN':['s3://'+ my_bucket +'/'+path_to_output+nome_output]*3,'NOME_PARAMETRO':['FILE_INPUT','PESI','PATH_TO_OUTPUT'],'VALORE_PARAMETRO':[file_input,pesi,path_to_output+nome_output]})\n",
    "                metadatati.to_csv('s3://'+ my_bucket +'/metadati/sistema/temperatura_norm/zeus/metadati/agg_ita_max_periodo_oss/'+idrun+'/metadati.csv',index=False)\n",
    "        \n",
    "#         agg_ita['mese'] = agg_ita['monthday'].str.slice(stop=2)\n",
    "#         agg_ita['giorno'] = agg_ita['monthday'].str.slice(start=3)\n",
    "#         agg_ita.drop(['monthday'],axis=1,inplace=True)\n",
    "#         print(\"oss: \",agg_ita)\n",
    "#         agg_ita = agg_ita[['mese','giorno','yhat_pesato','sum_pesi_gg']]\n",
    "\n",
    "        agg_ita.to_csv('s3://'+ my_bucket +'/'+path_to_output+nome_output,index=False)\n",
    "#         agg_ita.to_csv('prova_pesi_oss_yhat.csv',index=False)\n",
    "    print(\"Procedura terminata.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizio funzione aggregazione\n",
      "\n",
      "\n",
      "Aggregazione curve min_max periodo (curve * pesi)\n",
      "Lettura file di temperature T_max per provincia.\n",
      "Numero di provincia presenti: 103\n",
      "Procedura di ripartizione per peso avviata.\n",
      "Procedura terminata.\n"
     ]
    }
   ],
   "source": [
    "main_aggregazioni('./max_periodo_prov/200011_2020320210430084751/max_periodo.csv','preprocessato/sistema/temperature/external/file_config/pesi_temperature_provincia.csv','./')\n",
    "##### NUOVO PATH: 'preprocessato/sistema/temperatura/epson/temperatura'\n",
    "\n",
    "# main_aggregazioni('./mean_d_oss/best/mean_d_oss_20000101_20201231.csv','preprocessato/sistema/temperature/external/file_config/pesi_osservatorio.csv','./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>yhat_pesato</th>\n",
       "      <th>sum_pesi_gg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>16.372021</td>\n",
       "      <td>61012.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>16.213706</td>\n",
       "      <td>59846.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-03</td>\n",
       "      <td>16.083742</td>\n",
       "      <td>50884.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-04</td>\n",
       "      <td>15.956167</td>\n",
       "      <td>74279.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>15.763682</td>\n",
       "      <td>110692.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2021-09-26</td>\n",
       "      <td>17.281919</td>\n",
       "      <td>36763.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>17.082498</td>\n",
       "      <td>40653.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>16.914582</td>\n",
       "      <td>40653.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2021-09-29</td>\n",
       "      <td>16.746193</td>\n",
       "      <td>40653.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>16.577350</td>\n",
       "      <td>40653.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  yhat_pesato  sum_pesi_gg\n",
       "0    2020-10-01    16.372021     61012.56\n",
       "1    2020-10-02    16.213706     59846.21\n",
       "2    2020-10-03    16.083742     50884.64\n",
       "3    2020-10-04    15.956167     74279.95\n",
       "4    2020-10-05    15.763682    110692.15\n",
       "..          ...          ...          ...\n",
       "360  2021-09-26    17.281919     36763.39\n",
       "361  2021-09-27    17.082498     40653.14\n",
       "362  2021-09-28    16.914582     40653.14\n",
       "363  2021-09-29    16.746193     40653.14\n",
       "364  2021-09-30    16.577350     40653.14\n",
       "\n",
       "[365 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##agg yhat prov\n",
    "df=pd.read_csv('s3://zus-prod-s3/./agg_ita_norm_prov/20201001_20210930_20210430153315/agg_ita_norm_mean_prov.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>mese</th>\n",
       "      <th>giorno</th>\n",
       "      <th>yhat_pesato</th>\n",
       "      <th>sum_pesi_gg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.893271</td>\n",
       "      <td>10870226.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.916797</td>\n",
       "      <td>10463725.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.924331</td>\n",
       "      <td>10292466.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.915458</td>\n",
       "      <td>12201191.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.890546</td>\n",
       "      <td>12584855.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>4.934638</td>\n",
       "      <td>11210169.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>4.886945</td>\n",
       "      <td>13549053.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>4.803718</td>\n",
       "      <td>13273426.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>4.783585</td>\n",
       "      <td>12769365.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4.778235</td>\n",
       "      <td>12753726.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  mese  giorno  yhat_pesato  sum_pesi_gg\n",
       "0    2020-01-01     1       1     4.893271  10870226.87\n",
       "1    2020-01-02     1       2     4.916797  10463725.80\n",
       "2    2020-01-03     1       3     4.924331  10292466.45\n",
       "3    2020-01-04     1       4     4.915458  12201191.71\n",
       "4    2020-01-05     1       5     4.890546  12584855.58\n",
       "..          ...   ...     ...          ...          ...\n",
       "361  2020-12-27    12      27     4.934638  11210169.76\n",
       "362  2020-12-28    12      28     4.886945  13549053.07\n",
       "363  2020-12-29    12      29     4.803718  13273426.41\n",
       "364  2020-12-30    12      30     4.783585  12769365.60\n",
       "365  2020-12-31    12      31     4.778235  12753726.29\n",
       "\n",
       "[366 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##agg yhat oss\n",
    "df = pd.read_csv('s3://zus-prod-s3/./agg_ita_norm_oss/20200101_20201231_20210430155000/agg_ita_norm_mean_oss.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>mese</th>\n",
       "      <th>giorno</th>\n",
       "      <th>T_oss_pesato</th>\n",
       "      <th>sum_pesi_gg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5.840830</td>\n",
       "      <td>4985529.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6.934365</td>\n",
       "      <td>5811533.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>6.077228</td>\n",
       "      <td>5411733.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-04</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>6.648215</td>\n",
       "      <td>4993502.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-05</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>5.748887</td>\n",
       "      <td>5026077.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>7.401382</td>\n",
       "      <td>6138134.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>7.282950</td>\n",
       "      <td>5289071.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>6.380479</td>\n",
       "      <td>5289071.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>7.985894</td>\n",
       "      <td>5289071.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>5.952810</td>\n",
       "      <td>4358957.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  mese  giorno  T_oss_pesato  sum_pesi_gg\n",
       "0    2020-11-01    11       1      5.840830   4985529.89\n",
       "1    2020-11-02    11       2      6.934365   5811533.94\n",
       "2    2020-11-03    11       3      6.077228   5411733.53\n",
       "3    2020-11-04    11       4      6.648215   4993502.20\n",
       "4    2020-11-05    11       5      5.748887   5026077.96\n",
       "..          ...   ...     ...           ...          ...\n",
       "146  2020-03-27     3      27      7.401382   6138134.18\n",
       "147  2020-03-28     3      28      7.282950   5289071.79\n",
       "148  2020-03-29     3      29      6.380479   5289071.79\n",
       "149  2020-03-30     3      30      7.985894   5289071.79\n",
       "150  2020-03-31     3      31      5.952810   4358957.76\n",
       "\n",
       "[151 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max_periodo oss\n",
    "df = pd.read_csv('s3://zus-prod-s3/./agg_ita_max_periodo_oss/20200101_20201231_20210430160010/agg_ita_max_periodo_oss.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>mese</th>\n",
       "      <th>giorno</th>\n",
       "      <th>T_max_pesato</th>\n",
       "      <th>sum_pesi_gg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>18.569637</td>\n",
       "      <td>4728118.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>15.688982</td>\n",
       "      <td>5528785.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>16.444362</td>\n",
       "      <td>5153818.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-04</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>15.115535</td>\n",
       "      <td>4769805.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-05</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>15.778402</td>\n",
       "      <td>4799122.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2021-03-27</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>14.676287</td>\n",
       "      <td>5910285.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2021-03-28</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>16.534011</td>\n",
       "      <td>5854944.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>17.619028</td>\n",
       "      <td>5058770.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>16.738288</td>\n",
       "      <td>5058770.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>17.867928</td>\n",
       "      <td>5058770.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  mese  giorno  T_max_pesato  sum_pesi_gg\n",
       "0    2020-11-01    11       1     18.569637   4728118.35\n",
       "1    2020-11-02    11       2     15.688982   5528785.98\n",
       "2    2020-11-03    11       3     16.444362   5153818.60\n",
       "3    2020-11-04    11       4     15.115535   4769805.69\n",
       "4    2020-11-05    11       5     15.778402   4799122.81\n",
       "..          ...   ...     ...           ...          ...\n",
       "146  2021-03-27     3      27     14.676287   5910285.58\n",
       "147  2021-03-28     3      28     16.534011   5854944.24\n",
       "148  2021-03-29     3      29     17.619028   5058770.70\n",
       "149  2021-03-30     3      30     16.738288   5058770.70\n",
       "150  2021-03-31     3      31     17.867928   5058770.70\n",
       "\n",
       "[151 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##max periodo oss\n",
    "df = pd.read_csv('s3://zus-prod-s3/./agg_ita_max_periodo_prov/20201001_20210930_20210430160206/agg_ita_max_periodo_prov.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provincia</th>\n",
       "      <th>monthday</th>\n",
       "      <th>T_mean</th>\n",
       "      <th>T_min_abs</th>\n",
       "      <th>T_max_abs</th>\n",
       "      <th>gradi_giorno_yhat_mean</th>\n",
       "      <th>gradi_giorno_T_mean</th>\n",
       "      <th>std</th>\n",
       "      <th>var</th>\n",
       "      <th>yhat</th>\n",
       "      <th>percentile_10_T_mean</th>\n",
       "      <th>percentile_90_T_mean</th>\n",
       "      <th>percentile_10_yhat</th>\n",
       "      <th>percentile_90_yhat</th>\n",
       "      <th>c_i_95_T_mean_l</th>\n",
       "      <th>c_i_95_T_mean_u</th>\n",
       "      <th>c_i_95_yhat_l</th>\n",
       "      <th>c_i_95_yhat_u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9476</th>\n",
       "      <td>1</td>\n",
       "      <td>01-01</td>\n",
       "      <td>2.30</td>\n",
       "      <td>-5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.466278</td>\n",
       "      <td>15.70</td>\n",
       "      <td>2.745843</td>\n",
       "      <td>7.539656</td>\n",
       "      <td>2.533722</td>\n",
       "      <td>-1.220171</td>\n",
       "      <td>5.820171</td>\n",
       "      <td>-0.986449</td>\n",
       "      <td>6.053893</td>\n",
       "      <td>1.860574</td>\n",
       "      <td>2.739426</td>\n",
       "      <td>2.094295</td>\n",
       "      <td>2.973148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9477</th>\n",
       "      <td>2</td>\n",
       "      <td>01-01</td>\n",
       "      <td>1.90</td>\n",
       "      <td>-7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.980534</td>\n",
       "      <td>16.10</td>\n",
       "      <td>2.690717</td>\n",
       "      <td>7.239956</td>\n",
       "      <td>2.019466</td>\n",
       "      <td>-1.549499</td>\n",
       "      <td>5.349499</td>\n",
       "      <td>-1.430033</td>\n",
       "      <td>5.468964</td>\n",
       "      <td>1.469396</td>\n",
       "      <td>2.330604</td>\n",
       "      <td>1.588861</td>\n",
       "      <td>2.450070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9478</th>\n",
       "      <td>3</td>\n",
       "      <td>01-01</td>\n",
       "      <td>1.90</td>\n",
       "      <td>-7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.980534</td>\n",
       "      <td>16.10</td>\n",
       "      <td>2.690717</td>\n",
       "      <td>7.239956</td>\n",
       "      <td>2.019466</td>\n",
       "      <td>-1.549499</td>\n",
       "      <td>5.349499</td>\n",
       "      <td>-1.430033</td>\n",
       "      <td>5.468964</td>\n",
       "      <td>1.469396</td>\n",
       "      <td>2.330604</td>\n",
       "      <td>1.588861</td>\n",
       "      <td>2.450070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9479</th>\n",
       "      <td>4</td>\n",
       "      <td>01-01</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.800743</td>\n",
       "      <td>17.15</td>\n",
       "      <td>3.204552</td>\n",
       "      <td>10.269156</td>\n",
       "      <td>1.199257</td>\n",
       "      <td>-3.258236</td>\n",
       "      <td>4.958236</td>\n",
       "      <td>-2.908979</td>\n",
       "      <td>5.307493</td>\n",
       "      <td>0.337165</td>\n",
       "      <td>1.362835</td>\n",
       "      <td>0.686422</td>\n",
       "      <td>1.712092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9480</th>\n",
       "      <td>5</td>\n",
       "      <td>01-01</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.714037</td>\n",
       "      <td>16.00</td>\n",
       "      <td>2.683149</td>\n",
       "      <td>7.199289</td>\n",
       "      <td>2.285963</td>\n",
       "      <td>-1.439797</td>\n",
       "      <td>5.439797</td>\n",
       "      <td>-1.153834</td>\n",
       "      <td>5.725760</td>\n",
       "      <td>1.570607</td>\n",
       "      <td>2.429393</td>\n",
       "      <td>1.856570</td>\n",
       "      <td>2.715356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9574</th>\n",
       "      <td>99</td>\n",
       "      <td>01-01</td>\n",
       "      <td>4.25</td>\n",
       "      <td>-5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.356534</td>\n",
       "      <td>13.75</td>\n",
       "      <td>2.919758</td>\n",
       "      <td>8.524989</td>\n",
       "      <td>4.643466</td>\n",
       "      <td>0.506870</td>\n",
       "      <td>7.993130</td>\n",
       "      <td>0.900336</td>\n",
       "      <td>8.386596</td>\n",
       "      <td>3.782741</td>\n",
       "      <td>4.717259</td>\n",
       "      <td>4.176207</td>\n",
       "      <td>5.110724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9575</th>\n",
       "      <td>100</td>\n",
       "      <td>01-01</td>\n",
       "      <td>6.50</td>\n",
       "      <td>-1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.213907</td>\n",
       "      <td>11.50</td>\n",
       "      <td>2.993593</td>\n",
       "      <td>8.961600</td>\n",
       "      <td>6.786093</td>\n",
       "      <td>2.662214</td>\n",
       "      <td>10.337786</td>\n",
       "      <td>2.948307</td>\n",
       "      <td>10.623879</td>\n",
       "      <td>6.020925</td>\n",
       "      <td>6.979075</td>\n",
       "      <td>6.307018</td>\n",
       "      <td>7.265168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9576</th>\n",
       "      <td>101</td>\n",
       "      <td>01-01</td>\n",
       "      <td>10.15</td>\n",
       "      <td>3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.919250</td>\n",
       "      <td>7.85</td>\n",
       "      <td>2.552343</td>\n",
       "      <td>6.514456</td>\n",
       "      <td>10.080750</td>\n",
       "      <td>6.877896</td>\n",
       "      <td>13.422104</td>\n",
       "      <td>6.808646</td>\n",
       "      <td>13.352854</td>\n",
       "      <td>9.741540</td>\n",
       "      <td>10.558460</td>\n",
       "      <td>9.672290</td>\n",
       "      <td>10.489210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9577</th>\n",
       "      <td>102</td>\n",
       "      <td>01-01</td>\n",
       "      <td>8.70</td>\n",
       "      <td>-3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.180202</td>\n",
       "      <td>9.30</td>\n",
       "      <td>2.481955</td>\n",
       "      <td>6.160100</td>\n",
       "      <td>8.819798</td>\n",
       "      <td>5.518134</td>\n",
       "      <td>11.881866</td>\n",
       "      <td>5.637932</td>\n",
       "      <td>12.001664</td>\n",
       "      <td>8.302804</td>\n",
       "      <td>9.097196</td>\n",
       "      <td>8.422602</td>\n",
       "      <td>9.216993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9578</th>\n",
       "      <td>103</td>\n",
       "      <td>01-01</td>\n",
       "      <td>1.10</td>\n",
       "      <td>-10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.476025</td>\n",
       "      <td>16.90</td>\n",
       "      <td>2.822733</td>\n",
       "      <td>7.967822</td>\n",
       "      <td>1.523975</td>\n",
       "      <td>-2.518744</td>\n",
       "      <td>4.718744</td>\n",
       "      <td>-2.094769</td>\n",
       "      <td>5.142719</td>\n",
       "      <td>0.648269</td>\n",
       "      <td>1.551731</td>\n",
       "      <td>1.072243</td>\n",
       "      <td>1.975706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      provincia monthday  T_mean  T_min_abs  T_max_abs  \\\n",
       "9476          1    01-01    2.30         -5       10.0   \n",
       "9477          2    01-01    1.90         -7        8.0   \n",
       "9478          3    01-01    1.90         -7        8.0   \n",
       "9479          4    01-01    0.85         -9        8.0   \n",
       "9480          5    01-01    2.00         -6        9.0   \n",
       "...         ...      ...     ...        ...        ...   \n",
       "9574         99    01-01    4.25         -5       18.0   \n",
       "9575        100    01-01    6.50         -1       15.0   \n",
       "9576        101    01-01   10.15          3       17.0   \n",
       "9577        102    01-01    8.70         -3       16.0   \n",
       "9578        103    01-01    1.10        -10        9.0   \n",
       "\n",
       "      gradi_giorno_yhat_mean  gradi_giorno_T_mean       std        var  \\\n",
       "9476               15.466278                15.70  2.745843   7.539656   \n",
       "9477               15.980534                16.10  2.690717   7.239956   \n",
       "9478               15.980534                16.10  2.690717   7.239956   \n",
       "9479               16.800743                17.15  3.204552  10.269156   \n",
       "9480               15.714037                16.00  2.683149   7.199289   \n",
       "...                      ...                  ...       ...        ...   \n",
       "9574               13.356534                13.75  2.919758   8.524989   \n",
       "9575               11.213907                11.50  2.993593   8.961600   \n",
       "9576                7.919250                 7.85  2.552343   6.514456   \n",
       "9577                9.180202                 9.30  2.481955   6.160100   \n",
       "9578               16.476025                16.90  2.822733   7.967822   \n",
       "\n",
       "           yhat  percentile_10_T_mean  percentile_90_T_mean  \\\n",
       "9476   2.533722             -1.220171              5.820171   \n",
       "9477   2.019466             -1.549499              5.349499   \n",
       "9478   2.019466             -1.549499              5.349499   \n",
       "9479   1.199257             -3.258236              4.958236   \n",
       "9480   2.285963             -1.439797              5.439797   \n",
       "...         ...                   ...                   ...   \n",
       "9574   4.643466              0.506870              7.993130   \n",
       "9575   6.786093              2.662214             10.337786   \n",
       "9576  10.080750              6.877896             13.422104   \n",
       "9577   8.819798              5.518134             11.881866   \n",
       "9578   1.523975             -2.518744              4.718744   \n",
       "\n",
       "      percentile_10_yhat  percentile_90_yhat  c_i_95_T_mean_l  \\\n",
       "9476           -0.986449            6.053893         1.860574   \n",
       "9477           -1.430033            5.468964         1.469396   \n",
       "9478           -1.430033            5.468964         1.469396   \n",
       "9479           -2.908979            5.307493         0.337165   \n",
       "9480           -1.153834            5.725760         1.570607   \n",
       "...                  ...                 ...              ...   \n",
       "9574            0.900336            8.386596         3.782741   \n",
       "9575            2.948307           10.623879         6.020925   \n",
       "9576            6.808646           13.352854         9.741540   \n",
       "9577            5.637932           12.001664         8.302804   \n",
       "9578           -2.094769            5.142719         0.648269   \n",
       "\n",
       "      c_i_95_T_mean_u  c_i_95_yhat_l  c_i_95_yhat_u  \n",
       "9476         2.739426       2.094295       2.973148  \n",
       "9477         2.330604       1.588861       2.450070  \n",
       "9478         2.330604       1.588861       2.450070  \n",
       "9479         1.362835       0.686422       1.712092  \n",
       "9480         2.429393       1.856570       2.715356  \n",
       "...               ...            ...            ...  \n",
       "9574         4.717259       4.176207       5.110724  \n",
       "9575         6.979075       6.307018       7.265168  \n",
       "9576        10.558460       9.672290      10.489210  \n",
       "9577         9.097196       8.422602       9.216993  \n",
       "9578         1.551731       1.072243       1.975706  \n",
       "\n",
       "[103 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_old = pd.read_csv('s3://zus-prod-s3/preprocessato/utente/temperatura_norm/zeus/mean_d_prov/best/mean_d_prov_20000101_20201231.csv')\n",
    "df_old[df_old['monthday']==\"01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codice_oss</th>\n",
       "      <th>date</th>\n",
       "      <th>T_oss</th>\n",
       "      <th>to_groupby</th>\n",
       "      <th>mese</th>\n",
       "      <th>giorno</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>2009-11-01</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>2009-11-02</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>307</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>2009-11-03</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>308</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>2009-11-04</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>309</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2009-11-05</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>310</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>29</td>\n",
       "      <td>2012-03-27</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>87</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>29</td>\n",
       "      <td>2012-03-28</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>88</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>29</td>\n",
       "      <td>2012-03-29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>89</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>29</td>\n",
       "      <td>2012-03-30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>90</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>29</td>\n",
       "      <td>2012-03-31</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>91</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2718 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      codice_oss        date  T_oss  to_groupby  mese  giorno  dayofyear  year\n",
       "0             11  2009-11-01    8.0        2010    11       1        306  2009\n",
       "1             11  2009-11-02   13.0        2010    11       2        307  2009\n",
       "2             11  2009-11-03    8.5        2010    11       3        308  2009\n",
       "3             11  2009-11-04   11.5        2010    11       4        309  2009\n",
       "4             11  2009-11-05   10.5        2010    11       5        310  2009\n",
       "...          ...         ...    ...         ...   ...     ...        ...   ...\n",
       "2713          29  2012-03-27    6.0        2012     3      27         87  2012\n",
       "2714          29  2012-03-28    6.5        2012     3      28         88  2012\n",
       "2715          29  2012-03-29    4.0        2012     3      29         89  2012\n",
       "2716          29  2012-03-30    4.0        2012     3      30         90  2012\n",
       "2717          29  2012-03-31    7.5        2012     3      31         91  2012\n",
       "\n",
       "[2718 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "max_oss = pd.read_csv('s3://zus-prod-s3/./max_periodo_oss/200011_2020320210430092143/max_periodo.csv')\n",
    "max_oss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
