{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile main_gg.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "# from scipy import stats\n",
    "from datetime import datetime,timedelta\n",
    "import calendar as c\n",
    "import boto3\n",
    "\n",
    "def isdir_s3(bucket, key):\n",
    "    objs = list(bucket.objects.filter(Prefix=key))\n",
    "#     print('I am the master_dir')\n",
    "    return len(objs)\n",
    "\n",
    "def costruzione_file_da_mensile(source, inizio, fine):\n",
    "    bucketname = 'zus-prod-s3'\n",
    "    s3 = boto3.resource('s3')\n",
    "#     source = 'preprocessato/sistema/temperatura/epson/temperatura'\n",
    "    my_bucket = s3.Bucket(bucketname)\n",
    "    annomesi = pd.date_range(inizio, fine,freq='MS').strftime('%Y%m').tolist()\n",
    "    df = pd.DataFrame()\n",
    "    for am in annomesi:\n",
    "        if isdir_s3(my_bucket,source + '/' +str(am))>0:\n",
    "            df = df.append(pd.read_csv('s3://'+bucketname+'/'+source+'/'+str(am)+'/epson_best.csv'))\n",
    "    return df\n",
    "\n",
    "def compute_std_var(df_in,finestra_media_mobile_g,col):\n",
    "    df = df_in.copy()\n",
    "#     print(df_in)#.drop('provincia',axis=1).reset_index())\n",
    "    days = int(np.floor(finestra_media_mobile_g/2))\n",
    "    mds = sorted(df.monthday.unique())\n",
    "    min_md = df[df['date']==min(df['date'])]['monthday'].ravel()[0]\n",
    "    max_md = df[df['date']==max(df['date'])]['monthday'].ravel()[0]\n",
    "    df['isleap'] = 0\n",
    "    df['isleap'] = df.apply(lambda x: 1 if c.isleap(x['date'].year) else 0,axis=1)\n",
    "    to_append = pd.DataFrame()\n",
    "    for md in mds:\n",
    "#         print(md)\n",
    "        if md!='02-29':\n",
    "            lista = pd.date_range(datetime.strptime(str(md), \"%m-%d\")-timedelta(days=days), datetime.strptime(str(md), \"%m-%d\")+timedelta(days=days)).strftime(\"%m-%d\").tolist()\n",
    "            var = df[df.monthday.isin(lista)][col].var(ddof=0)\n",
    "#             print(df[df.monthday.isin(lista)])\n",
    "            std = np.sqrt(var)\n",
    "            to_append = to_append.append(pd.DataFrame({col+'_var':[var],col+'_std':[std]},index=[md]))\n",
    "        else:\n",
    "            lista = pd.date_range(datetime.strptime(str('02-22'), \"%m-%d\"), datetime.strptime(str('03-07'), \"%m-%d\")).strftime(\"%m-%d\").tolist()\n",
    "            lista = lista + ['02-29']\n",
    "            var = df[(df.monthday.isin(lista)) & (df.isleap == 1)][col].var(ddof=0)\n",
    "            std = np.sqrt(var)\n",
    "            to_append = to_append.append(pd.DataFrame({col+'_var':[var],col+'_std':[std]},index=[md]))\n",
    "    to_append.reset_index(inplace=True)\n",
    "    to_append.rename(columns={'index':'monthday'},inplace=True)\n",
    "    df = df.merge(to_append,on='monthday',how='left')\n",
    "    return df\n",
    "\n",
    "# def compute_std(df,finestra_media_mobile_g):\n",
    "# #     df['monthday'] = df['date'].dt.month.astype('str').str.pad(2, side='left', fillchar='0') + '-' + df['date'].dt.day.astype('str').str.pad(2, side='left', fillchar='0')\n",
    "#     return df.set_index(['dayofyear', 'year'], append=True).unstack().rolling(window=finestra_media_mobile_g, min_periods=1, center=True).var().stack().groupby('dayofyear')[['T_min_mean', 'T_max_mean','T_mean_m']].agg(lambda x: np.sqrt(np.mean(x)))    \n",
    "\n",
    "# def compute_var(df,finestra_media_mobile_g):\n",
    "#     return df.set_index(['dayofyear', 'year'], append=True).unstack().rolling(window=finestra_media_mobile_g, min_periods=1, center=True).var().stack().groupby('dayofyear')[['T_min_mean', 'T_max_mean','T_mean_m']].agg(lambda x: np.mean(x))\n",
    "\n",
    "def compute_std_month(df,finestra_media_mobile_m):\n",
    "#     print(df)\n",
    "    df = df.set_index(['dayofyear', 'year'], append=True).unstack().rolling(window=finestra_media_mobile_m, min_periods=1, center=True).var().stack().groupby('dayofyear')[['T_min_sum', 'T_max_sum','T_mean_sum']].agg(lambda x: np.sqrt(np.mean(x)))  \n",
    "    df = df.reset_index()\n",
    "    df.rename(columns={'T_min_sum':'std_t_min', 'T_max_sum':'std_t_max','T_mean_sum':'std_t_mean'},inplace=True)\n",
    "    return df\n",
    "    \n",
    "def compute_var_month(df,finestra_media_mobile_m):\n",
    "    df = df.set_index(['dayofyear', 'year'], append=True).unstack().rolling(window=finestra_media_mobile_m, min_periods=1, center=True).var().stack().groupby('dayofyear')[['T_min_sum', 'T_max_sum','T_mean_sum']].agg(lambda x: np.mean(x))  \n",
    "    df = df.reset_index()\n",
    "    df.rename(columns={'T_min_sum':'var_t_min', 'T_max_sum':'var_t_max','T_mean_sum':'var_t_mean'},inplace=True)\n",
    "    return df\n",
    "\n",
    "def compute_std_month_oss(df,finestra_media_mobile_m):\n",
    "    df = df.set_index(['dayofyear', 'year'],append=True).unstack().rolling(window=finestra_media_mobile_m, min_periods=1, center=True).var().stack().groupby('dayofyear')[['T_oss']].agg(lambda x: np.sqrt(np.mean(x)))  \n",
    "    df = df.reset_index()\n",
    "    df.rename(columns={'T_oss':'std_oss'},inplace=True)\n",
    "    return df\n",
    "    \n",
    "def compute_var_month_oss(df,finestra_media_mobile_m):\n",
    "    df = df.set_index(['dayofyear', 'year'],append=True).unstack().rolling(window=finestra_media_mobile_m, min_periods=1, center=True).var().stack().groupby('dayofyear')[['T_oss']].agg(lambda x: np.mean(x))  \n",
    "    df = df.reset_index()\n",
    "    df.rename(columns={'T_oss':'var_oss'},inplace=True)\n",
    "    return df\n",
    "\n",
    "def fit_harmonics(y, n_harmonics):\n",
    "    n = y.shape[0]\n",
    "    X = np.matrix([*[[np.sin(i*k/n*2*np.pi) for i in range(n)] for k in range(n_harmonics)], *[[np.cos(i*k/n*2*np.pi) for i in range(n)] for k in range(n_harmonics)]]).T\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    ols_model = sm.OLS(y, X).fit()\n",
    "    yhat = ols_model.predict(X)\n",
    "    \n",
    "    return yhat\n",
    "\n",
    "# Calcolo percentili\n",
    "def calcolo_percentili(df,column):\n",
    "    if column=='mean':\n",
    "        df['percentile_'+column+'_05_T_norm'] = df['T_'+column+'_m'] - 1.645 * df['std']\n",
    "        df['percentile_'+column+'_95_T_norm'] = df['T_'+column+'_m'] + 1.645 * df['std']\n",
    "        df['percentile_'+column+'_10_T_norm'] = df['T_'+column+'_m'] - 1.282 * df['std']\n",
    "        df['percentile_'+column+'_90_T_norm'] = df['T_'+column+'_m'] + 1.282 * df['std']\n",
    "        df['percentile_'+column+'_25_T_norm'] = df['T_'+column+'_m'] - 0.675 * df['std']\n",
    "        df['percentile_'+column+'_75_T_norm'] = df['T_'+column+'_m'] + 0.675 * df['std']\n",
    "    else:\n",
    "        df['percentile_'+column+'_05_T_norm'] = df['T_'+column+'_mean'] - 1.645 * df['std']\n",
    "        df['percentile_'+column+'_95_T_norm'] = df['T_'+column+'_mean'] + 1.645 * df['std']\n",
    "        df['percentile_'+column+'_10_T_norm'] = df['T_'+column+'_mean'] - 1.282 * df['std']\n",
    "        df['percentile_'+column+'_90_T_norm'] = df['T_'+column+'_mean'] + 1.282 * df['std']\n",
    "        df['percentile_'+column+'_25_T_norm'] = df['T_'+column+'_mean'] - 0.675 * df['std']\n",
    "        df['percentile_'+column+'_75_T_norm'] = df['T_'+column+'_mean'] + 0.675 * df['std']\n",
    "    return df\n",
    "\n",
    "def calcolo_percentili_yhat(df,column):\n",
    "    df['percentile_'+column+'_05_yhat'] = df['yhat_'+column] - 1.645 * df['std']\n",
    "    df['percentile_'+column+'_95_yhat'] = df['yhat_'+column] + 1.645 * df['std']\n",
    "    df['percentile_'+column+'_10_yhat'] = df['yhat_'+column] - 1.282 * df['std']\n",
    "    df['percentile_'+column+'_90_yhat'] = df['yhat_'+column] + 1.282 * df['std']\n",
    "    df['percentile_'+column+'_25_yhat'] = df['yhat_'+column] - 0.675 * df['std']\n",
    "    df['percentile_'+column+'_75_yhat'] = df['yhat_'+column] + 0.675 * df['std']\n",
    "    return df\n",
    "\n",
    "def calcolo_percentili_oss_yhat(df):\n",
    "    df['percentile_05_yhat'] = df['yhat'] - 1.645 * df['std']\n",
    "    df['percentile_95_yhat'] = df['yhat'] + 1.645 * df['std']\n",
    "    df['percentile_10_yhat'] = df['yhat'] - 1.282 * df['std']\n",
    "    df['percentile_90_yhat'] = df['yhat'] + 1.282 * df['std']\n",
    "    df['percentile_25_yhat'] = df['yhat'] - 0.675 * df['std']\n",
    "    df['percentile_75_yhat'] = df['yhat'] + 0.675 * df['std']\n",
    "    return df\n",
    "\n",
    "def calcolo_percentili_oss_T_oss(df):\n",
    "    df['percentile_05_T_oss'] = df['T_oss'] - 1.645 * df['std']\n",
    "    df['percentile_95_T_oss'] = df['T_oss'] + 1.645 * df['std']\n",
    "    df['percentile_10_T_oss'] = df['T_oss'] - 1.282 * df['std']\n",
    "    df['percentile_90_T_oss'] = df['T_oss'] + 1.282 * df['std']\n",
    "    df['percentile_25_T_oss'] = df['T_oss'] - 0.675 * df['std']\n",
    "    df['percentile_75_T_oss'] = df['T_oss'] + 0.675 * df['std']\n",
    "    return df\n",
    "\n",
    "def intervalli_confidenza(df,column):\n",
    "    df['c_i_95_'+column+'_l'] = df[column] - 1.96 * df['std']/np.sqrt(df['n_osservazioni'])\n",
    "    df['c_i_95_'+column+'_h'] = df[column] + 1.96 * df['std']/np.sqrt(df['n_osservazioni'])\n",
    "    return df\n",
    "\n",
    "#def lettura_temp_norm(file_t_norm,inizio,fine,finestra_media_mobile_g):\n",
    "def lettura_temp_norm(df,inizio,fine,finestra_media_mobile_g,tipo):\n",
    "\n",
    "#     df = pd.read_csv(file_t_norm)#,encoding='utf-16')\n",
    "    #df = pd.read_csv(file_t_norm)#,encoding='utf-16')\n",
    "    \n",
    "    #df.rename(columns={'TIME - Date':'date','Codice Provincia':'provincia','Temperature Min':'temp_min','Temperature Max':'temp_max'},inplace=True)\n",
    "\n",
    "\n",
    "    #df = costruzione_file_da_mensile(file_t_norm,inizio,fine)\n",
    "#     if t.lower() = 'prov':\n",
    "#         tipo = 'PROVINCIA'\n",
    "#     else:\n",
    "#         tipo = 'OSSERVATORIO'\n",
    "    df = df[['DATA',tipo.upper(),'TEMPERATURA_MAX','TEMPERATURA_MIN']]\n",
    "    \n",
    "    df.rename(columns={'DATA':'date',tipo.upper():tipo.lower(),'TEMPERATURA_MIN':'temp_min','TEMPERATURA_MAX':'temp_max'},inplace=True)\n",
    "    tipo = tipo.lower()\n",
    "    df = df[~df[tipo].isnull()]\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'],format='%Y-%m-%d')\n",
    "    df = df[(df['date']>=inizio) & (df['date']<=fine)]\n",
    "    df['T_mean'] = df[['temp_min', 'temp_max']].mean(axis=1)\n",
    "#     df.drop('Desc_Provincia',axis=1,inplace=True)\n",
    "\n",
    "    df = df.assign(\n",
    "        dayofyear=lambda x: (x.date).dt.dayofyear, # + pd.DateOffset(days=92)\n",
    "        year=lambda x: (x.date).dt.year, # + pd.DateOffset(days=92)\n",
    "    )\n",
    "#     df_con = df.assign(\n",
    "#         dayofyear=lambda x: (x.date + pd.DateOffset(days=92)).dt.dayofyear, # + pd.DateOffset(days=92)\n",
    "#         year=lambda x: (x.date + pd.DateOffset(days=92)).dt.year, # + pd.DateOffset(days=92)\n",
    "#     )\n",
    "\n",
    "#     QUA SOTTO METTERE <=9 PER OFFSET=92, SENZA OFFSET METTERE <=12\n",
    "    df['dayofyear'] = df.apply(lambda x: x['dayofyear']+1 if (c.isleap(x['year'])==False and x['date'].month>=3 and x['date'].month<=12) else x['dayofyear'],axis=1)\n",
    "    \n",
    "    df['monthyear'] = (df.date.dt.month).astype('str').str.pad(2, side='left', fillchar='0')+(df.year).astype('str')\n",
    "#     df_con['monthyear'] = (df_con.date.dt.month).astype('str').str.pad(2, side='left', fillchar='0')+(df_con.year).astype('str')\n",
    "    \n",
    "#     df.to_csv('df_senza_92.csv',index=False)\n",
    "#     df_con.to_csv('df_con_92.csv',index=False)\n",
    "#     ciao\n",
    "#     Raggruppo per provincia e monthyear\n",
    "    tmp = (df[['monthyear','date',tipo]].groupby(['monthyear',tipo]).count()).reset_index()\n",
    "    tmp['monthyear'] = tmp['monthyear'].astype('str')\n",
    "    tmp['monthyear'] = tmp['monthyear'].str.slice(stop=2)\n",
    "    tmp.rename(columns={'date':'n_anni','monthyear':'month'},inplace=True)\n",
    "    tmp['n_anni'] = 1\n",
    "    \n",
    "    tmp = tmp.groupby(['month',tipo]).count().reset_index()\n",
    "    \n",
    "    df = df.merge(tmp,on=[tipo],how='left')\n",
    "    \n",
    "    df['n_osservazioni'] = df['n_anni']*finestra_media_mobile_g\n",
    "\n",
    "    df.drop(['n_anni','month'],axis=1,inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df['monthday'] = df['date'].dt.month.astype('str').str.pad(2, side='left', fillchar='0') + '-' + df['date'].dt.day.astype('str').str.pad(2, side='left', fillchar='0')   \n",
    "    return df\n",
    "\n",
    "def lettura_osservatorio(df,inizio,fine,finestra_media_mobile_g):\n",
    "#     df_oss = pd.read_csv(file_oss)\n",
    "    #df_oss.rename(columns={'Cd Oss':'codice_oss','T Oss':'T_oss','Data':'date'},inplace=True)\n",
    "    \n",
    "    df_oss['date'] = df_oss['date'].astype('str')\n",
    "    df_oss['date'] = pd.to_datetime(df_oss['date'],format='%Y-%m-%d', exact=False)\n",
    "    df_oss = df_oss[(df_oss['date']>=inizio) & (df_oss['date']<=fine)]\n",
    "    df_oss = df_oss[~df_oss['codice_oss'].isnull()]\n",
    "\n",
    "    df['T_mean'] = df[['temp_min', 'temp_max']].mean(axis=1)\n",
    "    df.drop('Desc_Provincia',axis=1,inplace=True)\n",
    "    \n",
    "    df_oss = df_oss.assign(\n",
    "        dayofyear=lambda x: (x.date).dt.dayofyear, # + pd.DateOffset(days=92)\n",
    "        year=lambda x: (x.date).dt.year, # + pd.DateOffset(days=92)\n",
    "    )\n",
    "    \n",
    "    df_oss['dayofyear'] = df_oss.apply(lambda x: x['dayofyear']+1 if (c.isleap(x['year'])==False and x['date'].month>=3 and x['date'].month<=12) else x['dayofyear'],axis=1)\n",
    "    \n",
    "    df_oss.drop('Oss',axis=1,inplace=True)\n",
    "    df_oss['monthyear'] = (df_oss.date.dt.month).astype('str').str.pad(2, side='left', fillchar='0')+(df_oss.date.dt.year).astype('str')\n",
    "    tmp = (df_oss[['monthyear','date','codice_oss']].groupby(['monthyear','codice_oss']).count()).reset_index()\n",
    "    tmp.rename(columns={'date':'n_anni'},inplace=True) #,'monthyear':'month'\n",
    "    tmp['n_anni'] = 1\n",
    "    tmp['monthyear'] = tmp['monthyear'].astype('str')\n",
    "    tmp['month'] = tmp['monthyear'].str.slice(stop=2)\n",
    "\n",
    "    tmp = tmp.groupby(['month','codice_oss']).count().reset_index()\n",
    "    tmp.drop('monthyear',axis=1,inplace=True)\n",
    "    df_oss['month'] = df_oss['monthyear'].str.slice(stop=2)\n",
    "    df_oss = df_oss.merge(tmp,on=['codice_oss','month'],how='left')\n",
    "    \n",
    "    df_oss['n_osservazioni'] = df_oss['n_anni']*finestra_media_mobile_g\n",
    "    \n",
    "    df_oss.drop(['n_anni'],axis=1,inplace=True)\n",
    "    df_oss['monthday'] = df_oss['date'].dt.month.astype('str').str.pad(2, side='left', fillchar='0') + '-' + df_oss['date'].dt.day.astype('str').str.pad(2, side='left', fillchar='0')\n",
    "    return df_oss\n",
    "\n",
    "def calcolo_temp_norm_gg(file_t_norm,inizio,fine,finestra_media_mobile_g,t):\n",
    "    if t.lower()=='prov':\n",
    "        tipo = 'PROVINCIA'\n",
    "    else:\n",
    "        tipo='OSSERVATORIO'\n",
    "#     Calcolo temperature normali giornaliere\n",
    "    print(\"Lettura file temperature per \"+ str(tipo))\n",
    "    df = lettura_temp_norm(file_t_norm,inizio,fine,finestra_media_mobile_g,tipo)\n",
    "    tipo = tipo.lower()\n",
    "    print(\"Numero \"+tipo+\" presenti: \",df[tipo].nunique())\n",
    "    \n",
    "    print(\"Calcolo deviazione standard.\")\n",
    "    df_max = df.groupby(tipo).apply(compute_std_var, finestra_media_mobile_g=finestra_media_mobile_g, col='temp_max')[[tipo,'date','temp_max_var','temp_max_std']]\n",
    "    df_min = df.groupby(tipo).apply(compute_std_var, finestra_media_mobile_g=finestra_media_mobile_g, col='temp_min')[[tipo,'date','temp_min_var','temp_min_std']]\n",
    "    df_mean = df.groupby(tipo).apply(compute_std_var, finestra_media_mobile_g=finestra_media_mobile_g, col='T_mean')[[tipo,'date','T_mean_var','T_mean_std']]\n",
    "\n",
    "    df_max.drop(tipo,axis=1,inplace=True)\n",
    "    df_min.drop(tipo,axis=1,inplace=True)\n",
    "    df_mean.drop(tipo,axis=1,inplace=True)\n",
    "    \n",
    "    df_max.reset_index(inplace=True)\n",
    "    df_min.reset_index(inplace=True)\n",
    "    df_mean.reset_index(inplace=True)\n",
    "    \n",
    "    df = df.merge(df_max, on=[tipo,'date'], how='left')\n",
    "    df = df.merge(df_min, on=[tipo,'date'], how='left')\n",
    "    df = df.merge(df_mean, on=[tipo,'date'], how='left')\n",
    "    \n",
    "    df.rename(columns={'temp_max':'T_max_mean','temp_min':'T_min_mean','T_mean':'T_mean_m'},inplace=True)\n",
    "    \n",
    "#     df.to_csv(\"df_senza_92.csv\",index=False)\n",
    "    \n",
    "    max_min_gg = df.groupby(['dayofyear',tipo]).agg({'T_min_mean':['min'],'T_max_mean':['max']})\n",
    "    max_min_gg.columns = max_min_gg.columns.droplevel(0)\n",
    "    max_min_gg = max_min_gg.reset_index()\n",
    "    max_min_gg.rename(columns={'min':'T_min_abs','max':'T_max_abs'},inplace=True)\n",
    "    \n",
    "    print(\"Calcolo media giornaliera.\")\n",
    "    temp_norm = df.groupby(['dayofyear', tipo])[['T_min_mean', 'T_max_mean','T_mean_m', 'temp_max_std', 'temp_max_var', 'temp_min_std', 'temp_min_var', 'T_mean_std', 'T_mean_var']].mean().unstack().reindex(range(367)).interpolate(method='linear').stack()#.reset_index() #,'T_mean'\n",
    "    \n",
    "    province = temp_norm.reset_index([tipo])[tipo].unique()\n",
    "    finale = pd.DataFrame()\n",
    "\n",
    "    print(\"Inizio procedura di fit con armoniche di sesto grado.\")\n",
    "#     Fit armoniche di sesto grado per curve T_min, T_max e T_mean\n",
    "    for p in province:\n",
    "        temp_p = temp_norm.query('{} == {}'.format(tipo,p)).reset_index([tipo,'dayofyear'])#.assign(std_mean=lambda x: x['std'], iv_l=lambda x: (x['mean'] - 2*x['std'].rolling(window=15, center=True).mean()), iv_h=lambda x: (x['mean'] + 2*x['std'].rolling(window=15, center=True).mean()))\n",
    "        ###########################\n",
    "#         temp_p = temp_p.merge(tmp,on='')\n",
    "        ###########################\n",
    "        y_min = temp_p['T_min_mean'].values.ravel()\n",
    "        y_max = temp_p['T_max_mean'].values.ravel()\n",
    "        y_mean = temp_p['T_mean_m'].values.ravel()\n",
    "\n",
    "        x = temp_p.index\n",
    "        \n",
    "        yhat_min = fit_harmonics(y_min, 6)\n",
    "        yhat_max = fit_harmonics(y_max, 6)\n",
    "        yhat_mean = fit_harmonics(y_mean, 6)\n",
    "\n",
    "        temp_p['yhat_min'] = yhat_min\n",
    "        temp_p['yhat_max'] = yhat_max\n",
    "        temp_p['yhat_mean'] = yhat_mean\n",
    "        \n",
    "#         if p==1:\n",
    "# #             temp_p.to_csv('temp_p_con_92.csv',index=False)\n",
    "#             print(y_mean)\n",
    "\n",
    "        finale = finale.append(temp_p)\n",
    "        \n",
    "#     Calcolo gradi giorno\n",
    "\n",
    "#################\n",
    "#     ciao\n",
    "#################\n",
    "    print(\"Conversione in gradi giorno.\")\n",
    "    finale['gradi_giorno_yhat_mean'] = 0\n",
    "    finale['gradi_giorno_yhat_mean'] = finale.apply(lambda x: max(0,18-x['yhat_mean']),axis=1)\n",
    "    finale.reset_index(inplace=True)\n",
    "    \n",
    "    finale['gradi_giorno_T_mean'] = 0\n",
    "    finale['gradi_giorno_T_mean'] = finale.apply(lambda x: max(0,18-x['T_mean_m']),axis=1)\n",
    "    finale.reset_index(inplace=True)\n",
    "    \n",
    "    selezione = df[[tipo,'n_osservazioni']]\n",
    "    selezione = selezione.groupby(tipo).apply(highest_number)\n",
    "    selezione.drop_duplicates(inplace=True)\n",
    "    finale = finale.merge(selezione,on=[tipo],how='left')\n",
    "\n",
    "    temp_max = temp_norm[['T_max_mean', 'temp_max_std', 'temp_max_var']].rename(columns={'temp_max_std': 'std', 'temp_max_var': 'var'}).reset_index()\n",
    "    temp_min = temp_norm[['T_min_mean', 'temp_min_std', 'temp_min_var']].rename(columns={'temp_min_std': 'std', 'temp_min_var': 'var'}).reset_index()\n",
    "    temp_mean = temp_norm[['T_mean_m', 'T_mean_std', 'T_mean_var']].rename(columns={'T_mean_std': 'std', 'T_mean_var': 'var'}).reset_index()\n",
    "\n",
    "    temp_max = temp_max.merge(finale[['dayofyear',tipo,'yhat_max','n_osservazioni']],on=['dayofyear',tipo],how='left')\n",
    "    temp_min = temp_min.merge(finale[['dayofyear',tipo,'yhat_min','n_osservazioni']],on=['dayofyear',tipo],how='left')\n",
    "    temp_mean = temp_mean.merge(finale[['dayofyear',tipo,'yhat_mean','gradi_giorno_yhat_mean','gradi_giorno_T_mean','n_osservazioni']],on=['dayofyear',tipo],how='left')\n",
    "\n",
    "    print(\"Calcolo percentili per curve di minimo, massimo e media.\")\n",
    "    temp_max = calcolo_percentili(temp_max,'max')\n",
    "    temp_min = calcolo_percentili(temp_min,'min')\n",
    "    temp_mean = calcolo_percentili(temp_mean,'mean')\n",
    "\n",
    "    temp_max = calcolo_percentili_yhat(temp_max,'max')\n",
    "    temp_min = calcolo_percentili_yhat(temp_min,'min')\n",
    "    temp_mean = calcolo_percentili_yhat(temp_mean,'mean')\n",
    "\n",
    "    print(\"Calcolo intervalli di confidenza per curve di minimo, massimo e media.\")\n",
    "    temp_max = intervalli_confidenza(temp_max,'T_max_mean')\n",
    "    temp_min = intervalli_confidenza(temp_min,'T_min_mean')\n",
    "    temp_mean = intervalli_confidenza(temp_mean,'T_mean_m')\n",
    "    \n",
    "    temp_max = intervalli_confidenza(temp_max,'yhat_max')\n",
    "    temp_min = intervalli_confidenza(temp_min,'yhat_min')\n",
    "    temp_mean = intervalli_confidenza(temp_mean,'yhat_mean')\n",
    "    \n",
    "    prv = pd.DataFrame()\n",
    "    prv['dayofyear'] = range(1,367)\n",
    "    prv['monthday'] = pd.date_range('2020-01-01','2020-12-31').astype('str').str.slice(start=5) #'2019-10-01','2020-09-30' for offset=92!\n",
    "    \n",
    "    temp_max = temp_max.merge(prv,on='dayofyear',how='left')\n",
    "    temp_min = temp_min.merge(prv,on='dayofyear',how='left')\n",
    "    temp_mean = temp_mean.merge(prv,on='dayofyear',how='left')\n",
    "\n",
    "    temp_max['mese'] = temp_max['monthday'].str.slice(stop=2).astype('int')\n",
    "    temp_max['giorno'] = temp_max['monthday'].str.slice(start=-2).astype('int')\n",
    "    \n",
    "    temp_min['mese'] = temp_min['monthday'].str.slice(stop=2).astype('int')\n",
    "    temp_min['giorno'] = temp_min['monthday'].str.slice(start=-2).astype('int')\n",
    "    \n",
    "    temp_mean['mese'] = temp_mean['monthday'].str.slice(stop=2).astype('int')\n",
    "    temp_mean['giorno'] = temp_mean['monthday'].str.slice(start=-2).astype('int')\n",
    "\n",
    "    temp_max = temp_max.merge(max_min_gg,on=['dayofyear',tipo],how='left')\n",
    "    temp_min = temp_min.merge(max_min_gg,on=['dayofyear',tipo],how='left')\n",
    "    temp_mean = temp_mean.merge(max_min_gg,on=['dayofyear',tipo],how='left')\n",
    "\n",
    "    temp_max = temp_max[['dayofyear','mese','giorno',tipo,'T_max_mean','T_min_abs','T_max_abs','std','var','yhat_max','percentile_max_10_T_norm','percentile_max_90_T_norm','percentile_max_10_yhat','percentile_max_90_yhat','c_i_95_T_max_mean_l','c_i_95_T_max_mean_h','c_i_95_yhat_max_l','c_i_95_yhat_max_h']]\n",
    "    temp_min = temp_min[['dayofyear','mese','giorno',tipo,'T_min_mean','T_min_abs','T_max_abs','std','var','yhat_min','percentile_min_10_T_norm','percentile_min_90_T_norm','percentile_min_10_yhat','percentile_min_90_yhat','c_i_95_T_min_mean_l','c_i_95_T_min_mean_h','c_i_95_yhat_min_l','c_i_95_yhat_min_h']]\n",
    "    temp_mean = temp_mean[['dayofyear','mese','giorno',tipo,'T_mean_m','T_min_abs','T_max_abs','gradi_giorno_yhat_mean','gradi_giorno_T_mean','std','var','yhat_mean','percentile_mean_10_T_norm','percentile_mean_90_T_norm','percentile_mean_10_yhat','percentile_mean_90_yhat','c_i_95_T_mean_m_l','c_i_95_T_mean_m_h','c_i_95_yhat_mean_l','c_i_95_yhat_mean_h']]\n",
    "    \n",
    "#     temp_max.rename(columns={'T_min_abs':'t_min_abs','T_max_abs':'t_max_abs','T_max_mean':'t_mean','yhat_max':'yhat','percentile_max_10_T_norm':'percentile_10_t_mean','percentile_max_90_T_norm':'percentile_90_t_mean','percentile_max_10_yhat':'percentile_10_yhat','percentile_max_90_yhat':'percentile_90_yhat','c_i_95_T_max_mean_l':'c_i_95_t_mean_l','c_i_95_T_max_mean_h':'c_i_95_t_mean_u','c_i_95_yhat_max_l':'c_i_95_yhat_l','c_i_95_yhat_max_h':'c_i_95_yhat_u'},inplace=True)\n",
    "#     temp_min.rename(columns={'T_min_abs':'t_min_abs','T_max_abs':'t_max_abs','T_min_mean':'t_mean','yhat_min':'yhat','percentile_min_10_T_norm':'percentile_10_t_mean','percentile_min_90_T_norm':'percentile_90_t_mean','percentile_min_10_yhat':'percentile_10_yhat','percentile_min_90_yhat':'percentile_90_yhat','c_i_95_T_min_mean_l':'c_i_95_t_mean_l','c_i_95_T_min_mean_h':'c_i_95_t_mean_u','c_i_95_yhat_min_l':'c_i_95_yhat_l','c_i_95_yhat_min_h':'c_i_95_yhat_u'},inplace=True)\n",
    "#     temp_mean.rename(columns={'T_min_abs':'t_min_abs','T_max_abs':'t_max_abs','T_mean_m':'t_mean','yhat_mean':'yhat','percentile_mean_10_T_norm':'percentile_10_t_mean','percentile_mean_90_T_norm':'percentile_90_t_mean','percentile_mean_10_yhat':'percentile_10_yhat','percentile_mean_90_yhat':'percentile_90_yhat','c_i_95_T_mean_m_l':'c_i_95_t_mean_l','c_i_95_T_mean_m_h':'c_i_95_t_mean_u','c_i_95_yhat_mean_l':'c_i_95_yhat_l','c_i_95_yhat_mean_h':'c_i_95_yhat_u'},inplace=True)\n",
    "\n",
    "    return temp_max,temp_min,temp_mean\n",
    "\n",
    "\n",
    "def highest_number(df):\n",
    "    df['n_osservazioni'] = df.n_osservazioni.max()\n",
    "    return df\n",
    "\n",
    "def calcolo_oss_gg(file_oss,inizio,fine,finestra_media_mobile_g):\n",
    "\n",
    "    print(\"Lettura file temperature per osservatorio.\")\n",
    "    df_oss = lettura_osservatorio(file_oss,inizio,fine,finestra_media_mobile_g)\n",
    "    \n",
    "    print(\"Numero osservatori presenti: \",df_oss['codice_oss'].nunique())\n",
    "\n",
    "    df_oss = df_oss.assign(\n",
    "        dayofyear=lambda x: (x.date).dt.dayofyear, # + pd.DateOffset(days=92)\n",
    "        year=lambda x: (x.date).dt.year, # + pd.DateOffset(days=92)\n",
    "    )\n",
    "    \n",
    "    print(\"Calcolo deviazione standard.\")\n",
    "    df_oss_std_var = df_oss.groupby('codice_oss').apply(compute_std_var, finestra_media_mobile_g=finestra_media_mobile_g, col='T_oss')[['codice_oss','date','T_oss_var','T_oss_std']]\n",
    "    \n",
    "    df_oss_std_var.drop('codice_oss',axis=1,inplace=True)\n",
    "\n",
    "    df_oss_std_var.reset_index(inplace=True)\n",
    "    df_oss = df_oss.merge(df_oss_std_var,on=['codice_oss','date'],how='left')\n",
    "\n",
    "    print(\"Calcolo media giornaliera.\")\n",
    "    temp_oss = df_oss.groupby(['dayofyear', 'codice_oss'])[['T_oss','T_oss_var','T_oss_std']].mean().unstack().reindex(range(367)).interpolate(method='linear').stack() #,'T_mean'\n",
    "\n",
    "    osservatori = temp_oss.reset_index(['codice_oss']).codice_oss.unique()\n",
    "    finale_oss = pd.DataFrame()\n",
    "\n",
    "    print(\"Inizio procedura di fit con armoniche di sesto grado.\")\n",
    "    for o in osservatori:\n",
    "        temp_o = temp_oss.query('codice_oss == {}'.format(o)).reset_index(['codice_oss'])#.assign(std_mean=lambda x: x['std'], iv_l=lambda x: (x['mean'] - 2*x['std'].rolling(window=15, center=True).mean()), iv_h=lambda x: (x['mean'] + 2*x['std'].rolling(window=15, center=True).mean()))\n",
    "\n",
    "        y = temp_o['T_oss'].values.ravel()\n",
    "        x = temp_o.index\n",
    "        \n",
    "        yhat = fit_harmonics(y, 6)\n",
    "\n",
    "        temp_o['yhat'] = yhat\n",
    "\n",
    "        finale_oss = finale_oss.append(temp_o)\n",
    "        \n",
    "    print(\"Conversione in gradi giorno.\")\n",
    "    finale_oss['gradi_giorno_yhat'] = 0\n",
    "    finale_oss['gradi_giorno_yhat'] = finale_oss.apply(lambda x: max(0,18-x['yhat']),axis=1)\n",
    "    finale_oss.reset_index(inplace=True)#[finale['T_mean_m']>=18]\n",
    "\n",
    "    finale_oss['gradi_giorno_T_oss'] = 0\n",
    "    finale_oss['gradi_giorno_T_oss'] = finale_oss.apply(lambda x: max(0,18-x['T_oss']),axis=1)\n",
    "    finale_oss.reset_index(inplace=True)#[finale['T_mean_m']>=18]\n",
    "    \n",
    "    selezione = df_oss[['codice_oss','n_osservazioni']]\n",
    "    selezione = selezione.groupby('codice_oss').apply(highest_number)\n",
    "    selezione.drop_duplicates(inplace=True)\n",
    "        \n",
    "    finale_oss = finale_oss.merge(selezione,on=['codice_oss'],how='left')\n",
    "\n",
    "    temp_oss = temp_oss.reset_index()\n",
    "    temp_oss.drop_duplicates(inplace=True)\n",
    "    temp_oss = temp_oss.set_index(['dayofyear','codice_oss'])\n",
    "\n",
    "    temp_oss_sv = temp_oss[['T_oss', 'T_oss_std', 'T_oss_var']].rename(columns={'T_oss_std': 'std', 'T_oss_var': 'var'}).reset_index()\n",
    "    temp_oss_sv = temp_oss_sv.merge(finale_oss[['dayofyear','codice_oss','yhat','gradi_giorno_T_oss','gradi_giorno_yhat','n_osservazioni']],on=['dayofyear','codice_oss'],how='left')\n",
    "\n",
    "    temp_oss_sv.drop_duplicates(inplace=True)\n",
    "\n",
    "    print(\"Calcolo percentili per curve di minimo, massimo e media.\")\n",
    "    temp_oss_sv = calcolo_percentili_oss_yhat(temp_oss_sv)\n",
    "    temp_oss_sv = calcolo_percentili_oss_T_oss(temp_oss_sv)\n",
    "    \n",
    "    print(\"Calcolo intervalli di confidenza per curve di minimo, massimo e media.\")\n",
    "    temp_oss_sv_T_oss = intervalli_confidenza(temp_oss_sv,'T_oss')\n",
    "    temp_oss_sv_yhat = intervalli_confidenza(temp_oss_sv,'yhat')\n",
    "    \n",
    "    prv = pd.DataFrame()\n",
    "    prv['dayofyear'] = range(1,367)\n",
    "    prv['monthday'] = pd.date_range('2020-01-01','2020-12-31').astype('str').str.slice(start=5)\n",
    "\n",
    "    temp_oss_sv_yhat = temp_oss_sv_yhat.merge(prv,on='dayofyear',how='left')\n",
    "    \n",
    "    temp_oss_sv_yhat['mese'] = temp_oss_sv_yhat['monthday'].str.slice(stop=2).astype('int')\n",
    "    temp_oss_sv_yhat['giorno'] = temp_oss_sv_yhat['monthday'].str.slice(start=-2).astype('int')\n",
    "    \n",
    "    temp_oss_sv_yhat = temp_oss_sv_yhat[['dayofyear','mese','giorno','codice_oss','gradi_giorno_yhat','gradi_giorno_T_oss','T_oss','std','var','yhat','percentile_10_yhat','percentile_90_yhat','percentile_10_T_oss','percentile_90_T_oss','c_i_95_T_oss_l','c_i_95_T_oss_h','c_i_95_yhat_l','c_i_95_yhat_h']]\n",
    "    \n",
    "    return temp_oss_sv_yhat\n",
    "\n",
    "def main_gg(file_input,inizio,fine,finestra_media_mobile_g,path_to_output,tipo):\n",
    "    \n",
    "    print('Funzione dedicata al calcolo delle temperature giornaliere e mensili.')\n",
    "    print('\\n')\n",
    "    \n",
    "    my_bucket = 'zus-prod-s3'\n",
    "    \n",
    "    finestra_media_mobile_g = int(finestra_media_mobile_g)\n",
    "    \n",
    "    inizio_dt = pd.to_datetime(inizio,format=\"%Y-%m-%d\")\n",
    "    fine_dt = pd.to_datetime(fine,format=\"%Y-%m-%d\")\n",
    "    \n",
    "    now = str(datetime.now())[0:-7].replace('-','').replace(' ','').replace(':','')\n",
    "    \n",
    "    file_name_out = inizio.replace('-','') + '_' + fine.replace('-','') + '_' + str(datetime.now())[0:-7].replace('-','').replace(' ','').replace(':','')\n",
    "        \n",
    "    #df = pd.read_csv('s3://'+ my_bucket +'/'+file_input)#,encoding='utf-16')\n",
    "    df = costruzione_file_da_mensile(file_input,inizio,fine)\n",
    "    \n",
    "    #if 'Codice Provincia' in df.columns:\n",
    "    #if 'PROVINCIA' in df.columns:\n",
    "    #if tipo.upper() == 'PROVINCIA':\n",
    "    print('Calcolo temperatura normale giornaliera per '+str(tipo)+' con funzioni armoniche di 6^ grado')\n",
    "#         temp_max_norm, temp_min_norm, temp_mean_norm = calcolo_temp_norm_gg('s3://'+ my_bucket +'/'+file_input,inizio_dt,fine_dt,finestra_media_mobile_g)\n",
    "    temp_max_norm, temp_min_norm, temp_mean_norm = calcolo_temp_norm_gg(df,inizio_dt,fine_dt,finestra_media_mobile_g,tipo)\n",
    "\n",
    "#         temp_max_norm.drop('dayofyear',inplace=True,axis=1)\n",
    "#         temp_min_norm.drop('dayofyear',inplace=True,axis=1)\n",
    "#         temp_mean_norm.drop('dayofyear',inplace=True,axis=1)\n",
    "\n",
    "    temp_max_norm.to_csv('s3://'+ my_bucket +'/'+path_to_output+'max_d_'+tipo+'/'+file_name_out+'/max_d_'+tipo+'.csv',index=False)\n",
    "    idrun_max = path_to_output+'/max_d_'+tipo+'/'+file_name_out+'/max_d_'+tipo+'.csv'\n",
    "    metadatati_max = pd.DataFrame(data={'CATEGORIA':['TEMPERATURA_NORM']*4,'FLUSSO':['MAX_D_'+tipo.upper()]*4,'TIMESTAMP':[now]*4,'ID':['TEMPERATURA_NORM_MAX_D_'+tipo.upper()+'_'+now]*4,'PATH':[idrun_max]*4,'NOME_PARAMETRO':['INIZIO_INIZIO','INIZIO_FINE','FINESTRA_MEDIA_MOBILE_G','PATH_TO_OUTPUT'],'VALORE_PARAMETRO':[inizio,fine,finestra_media_mobile_g,path_to_output]})\n",
    "    metadatati_max.to_csv('s3://'+ my_bucket +'/metadati/sistema/temperatura_norm/zeus/metadati/max_d_'+tipo+'/'+file_name_out+'/metadati.csv',index=False)\n",
    "    #metadatati_max.to_csv('./metadati/metadati_prov_gg_max.csv',index=False)\n",
    "    temp_min_norm.to_csv('s3://'+ my_bucket +'/'+path_to_output+'min_d_'+tipo+'/'+file_name_out+'/min_d'+tipo+'.csv',index=False)\n",
    "    idrun_min = path_to_output+'min_d_prov/'+file_name_out+'/min_d_'+tipo+'.csv'\n",
    "    metadatati_min = pd.DataFrame(data={'CATEGORIA':['TEMPERATURA_NORM']*4,'FLUSSO':['MIN_D_'+tipo.upper()]*4,'TIMESTAMP':[now]*4,'ID':['TEMPERATURA_NORM_MIN_D_'+tipo.upper()+'_'+now]*4,'PATH':[idrun_min]*4,'NOME_PARAMETRO':['INIZIO_INIZIO','INIZIO_FINE','FINESTRA_MEDIA_MOBILE_G','PATH_TO_OUTPUT'],'VALORE_PARAMETRO':[inizio,fine,finestra_media_mobile_g,path_to_output]})\n",
    "    metadatati_min.to_csv('s3://'+ my_bucket +'/metadati/sistema/temperatura_norm/zeus/metadati/min_d'+tipo+'/'+file_name_out+'/metadati.csv',index=False)\n",
    "    #metadatati_min.to_csv('./metadati/metadati_prov_gg_min.csv',index=False)\n",
    "\n",
    "    temp_mean_norm.to_csv('s3://'+ my_bucket +'/'+path_to_output+'mean_d_'+tipo+'/'+file_name_out+'/mean_d_'+tipo+'.csv',index=False)\n",
    "    idrun_mean = path_to_output+'mean_d_prov/'+file_name_out+'/mean_d_'+tipo+'.csv'\n",
    "    metadatati_mean = pd.DataFrame(data={'CATEGORIA':['TEMPERATURA_NORM']*4,'FLUSSO':['MEAN_D_'+tipo.upper()]*4,'TIMESTAMP':[now]*4,'ID':['TEMPERATURA_NORM_MEAN_D_'+tipo.upper()+'_'+now]*4,'PATH':[idrun_mean]*4,'NOME_PARAMETRO':['INIZIO_INIZIO','INIZIO_FINE','FINESTRA_MEDIA_MOBILE_G','PATH_TO_OUTPUT'],'VALORE_PARAMETRO':[inizio,fine,finestra_media_mobile_g,path_to_output]})\n",
    "    #metadatati_mean.to_csv('./metadati/metadati_prov_gg_mean.csv',index=False)\n",
    "    metadatati_mean.to_csv('s3://'+ my_bucket +'/metadati/sistema/temperatura_norm/zeus/metadati/mean_d_'+tipo+'/'+file_name_out+'/metadati.csv',index=False)\n",
    "#         temp_max_norm.to_csv('prova_gg_max.csv',index=False)\n",
    "#         temp_min_norm.to_csv('prova_gg_min.csv',index=False)\n",
    "#         temp_mean_norm.to_csv('prova_gg_mean.csv',index=False)\n",
    "    print('\\n')\n",
    "#     else:\n",
    "#         print('Calcolo osservatorio giornaliero con funzioni armoniche di 6^ grado')\n",
    "#         temp_oss_sv = calcolo_oss_gg('s3://'+ my_bucket +'/'+file_input,inizio_dt,fine_dt,finestra_media_mobile_g)\n",
    "#         #temp_oss_sv.drop(columns='dayofyear',inplace=True,axis=1)\n",
    "        \n",
    "#         temp_oss_sv.to_csv('s3://'+ my_bucket +'/'+path_to_output+'mean_d_'+tipo+'/'+file_name_out+'/mean_d_'+tipo+'.csv',index=False)\n",
    "#         idrun = path_to_output+'mean_d_oss/'+file_name_out+'/mean_d_'+tipo+'.csv'\n",
    "#         metadati = pd.DataFrame(data={'CATEGORIA':['TEMPERATURA_NORM']*4,'FLUSSO':['MEAN_D_'+tipo.upper()]*4,'TIMESTAMP':[now]*4,'ID':['TEMPERATURA_NORM_MEAN_D_'+tipo.upper()+'_'+now]*4,'PATH':[idrun]*4,'NOME_PARAMETRO':['INIZIO','FINE','FINESTRA_MEDIA_MOBILE_G','PATH_TO_OUTPUT'],'VALORE_PARAMETRO':[inizio,fine,finestra_media_mobile_g,path_to_output]})\n",
    "#         metadati.to_csv('s3://'+ my_bucket +'/metadati/sistema/zeus/temperatura_norm/zeus/metadati/mean_d_'+tipo+'oss/'+file_name_out+'/metadati.csv',index=False)\n",
    "#         #metadati.to_csv('./metadati/metadati_oss_gg_max.csv',index=False)\n",
    "\n",
    "#         #         temp_oss_sv.to_csv('prova_gg_oss.csv',index=False)\n",
    "#         print('\\n')\n",
    "    print(\"Procedura terminata.\")\n",
    "    \n",
    "#     return temp_max_norm, temp_min_norm, temp_mean_norm, temp_oss_sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funzione dedicata al calcolo delle temperature giornaliere e mensili.\n",
      "\n",
      "\n",
      "Calcolo temperatura normale giornaliera per prov con funzioni armoniche di 6^ grado\n",
      "Lettura file temperature per PROVINCIA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:4133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero provincia presenti:  102\n",
      "Calcolo deviazione standard.\n",
      "Calcolo media giornaliera.\n",
      "Inizio procedura di fit con armoniche di sesto grado.\n",
      "Conversione in gradi giorno.\n",
      "Calcolo percentili per curve di minimo, massimo e media.\n",
      "Calcolo intervalli di confidenza per curve di minimo, massimo e media.\n",
      "\n",
      "\n",
      "Procedura terminata.\n"
     ]
    }
   ],
   "source": [
    "#main_gg('preprocessato/sistema/temperatura_norm/zeus/storico/T_x_OSS_new.csv','2018-01-01','2020-12-31',15,'./')\n",
    "main_gg('preprocessato/sistema/temperatura/epson/temperatura','2000-01-01','2020-12-31',15,'epson_centralizzato/','prov')\n",
    "##### NUOVO PATH: 'preprocessato/sistema/temperatura/epson/temperatura'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>mese</th>\n",
       "      <th>giorno</th>\n",
       "      <th>codice_oss</th>\n",
       "      <th>gradi_giorno_yhat</th>\n",
       "      <th>gradi_giorno_T_oss</th>\n",
       "      <th>T_oss</th>\n",
       "      <th>std</th>\n",
       "      <th>var</th>\n",
       "      <th>yhat</th>\n",
       "      <th>percentile_10_yhat</th>\n",
       "      <th>percentile_90_yhat</th>\n",
       "      <th>percentile_10_T_oss</th>\n",
       "      <th>percentile_90_T_oss</th>\n",
       "      <th>c_i_95_T_oss_l</th>\n",
       "      <th>c_i_95_T_oss_h</th>\n",
       "      <th>c_i_95_yhat_l</th>\n",
       "      <th>c_i_95_yhat_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>14.849695</td>\n",
       "      <td>15.487500</td>\n",
       "      <td>2.512500</td>\n",
       "      <td>2.746581</td>\n",
       "      <td>7.543705</td>\n",
       "      <td>3.150305</td>\n",
       "      <td>-0.370811</td>\n",
       "      <td>6.671421</td>\n",
       "      <td>-1.008616</td>\n",
       "      <td>6.033616</td>\n",
       "      <td>2.209186</td>\n",
       "      <td>2.815814</td>\n",
       "      <td>2.846990</td>\n",
       "      <td>3.453619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>14.262341</td>\n",
       "      <td>15.262500</td>\n",
       "      <td>2.737500</td>\n",
       "      <td>2.591916</td>\n",
       "      <td>6.718030</td>\n",
       "      <td>3.737659</td>\n",
       "      <td>0.414823</td>\n",
       "      <td>7.060496</td>\n",
       "      <td>-0.585337</td>\n",
       "      <td>6.060337</td>\n",
       "      <td>2.451266</td>\n",
       "      <td>3.023734</td>\n",
       "      <td>3.451425</td>\n",
       "      <td>4.023894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>16.307430</td>\n",
       "      <td>17.275000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>2.819506</td>\n",
       "      <td>7.949612</td>\n",
       "      <td>1.692570</td>\n",
       "      <td>-1.922036</td>\n",
       "      <td>5.307176</td>\n",
       "      <td>-2.889606</td>\n",
       "      <td>4.339606</td>\n",
       "      <td>0.413632</td>\n",
       "      <td>1.036368</td>\n",
       "      <td>1.381202</td>\n",
       "      <td>2.003938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>13.618532</td>\n",
       "      <td>13.962500</td>\n",
       "      <td>4.037500</td>\n",
       "      <td>2.676694</td>\n",
       "      <td>7.164693</td>\n",
       "      <td>4.381468</td>\n",
       "      <td>0.949946</td>\n",
       "      <td>7.812990</td>\n",
       "      <td>0.605978</td>\n",
       "      <td>7.469022</td>\n",
       "      <td>3.741903</td>\n",
       "      <td>4.333097</td>\n",
       "      <td>4.085872</td>\n",
       "      <td>4.677065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>11.077590</td>\n",
       "      <td>10.725000</td>\n",
       "      <td>7.275000</td>\n",
       "      <td>3.039290</td>\n",
       "      <td>9.237281</td>\n",
       "      <td>6.922410</td>\n",
       "      <td>3.026041</td>\n",
       "      <td>10.818780</td>\n",
       "      <td>3.378631</td>\n",
       "      <td>11.171369</td>\n",
       "      <td>6.939361</td>\n",
       "      <td>7.610639</td>\n",
       "      <td>6.586771</td>\n",
       "      <td>7.258050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6583</th>\n",
       "      <td>366</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>8.839712</td>\n",
       "      <td>10.166667</td>\n",
       "      <td>7.833333</td>\n",
       "      <td>2.986321</td>\n",
       "      <td>8.918112</td>\n",
       "      <td>9.160288</td>\n",
       "      <td>5.331825</td>\n",
       "      <td>12.988752</td>\n",
       "      <td>4.004870</td>\n",
       "      <td>11.661797</td>\n",
       "      <td>7.503544</td>\n",
       "      <td>8.163123</td>\n",
       "      <td>8.830499</td>\n",
       "      <td>9.490078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6584</th>\n",
       "      <td>366</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>26</td>\n",
       "      <td>8.243516</td>\n",
       "      <td>8.875000</td>\n",
       "      <td>9.125000</td>\n",
       "      <td>3.145037</td>\n",
       "      <td>9.891260</td>\n",
       "      <td>9.756484</td>\n",
       "      <td>5.724546</td>\n",
       "      <td>13.788422</td>\n",
       "      <td>5.093062</td>\n",
       "      <td>13.156938</td>\n",
       "      <td>8.777683</td>\n",
       "      <td>9.472317</td>\n",
       "      <td>9.409167</td>\n",
       "      <td>10.103802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6585</th>\n",
       "      <td>366</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>12.737714</td>\n",
       "      <td>14.141667</td>\n",
       "      <td>3.858333</td>\n",
       "      <td>3.438749</td>\n",
       "      <td>11.824998</td>\n",
       "      <td>5.262286</td>\n",
       "      <td>0.853810</td>\n",
       "      <td>9.670763</td>\n",
       "      <td>-0.550143</td>\n",
       "      <td>8.266810</td>\n",
       "      <td>3.478580</td>\n",
       "      <td>4.238086</td>\n",
       "      <td>4.882533</td>\n",
       "      <td>5.642040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6586</th>\n",
       "      <td>366</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>5.406048</td>\n",
       "      <td>6.541667</td>\n",
       "      <td>11.458333</td>\n",
       "      <td>2.631762</td>\n",
       "      <td>6.926171</td>\n",
       "      <td>12.593952</td>\n",
       "      <td>9.220033</td>\n",
       "      <td>15.967870</td>\n",
       "      <td>8.084415</td>\n",
       "      <td>14.832252</td>\n",
       "      <td>11.167699</td>\n",
       "      <td>11.748968</td>\n",
       "      <td>12.303317</td>\n",
       "      <td>12.884586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6587</th>\n",
       "      <td>366</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>6.929239</td>\n",
       "      <td>9.041667</td>\n",
       "      <td>8.958333</td>\n",
       "      <td>2.762812</td>\n",
       "      <td>7.633129</td>\n",
       "      <td>11.070761</td>\n",
       "      <td>7.528836</td>\n",
       "      <td>14.612686</td>\n",
       "      <td>5.416409</td>\n",
       "      <td>12.500258</td>\n",
       "      <td>8.653226</td>\n",
       "      <td>9.263440</td>\n",
       "      <td>10.765654</td>\n",
       "      <td>11.375868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6588 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dayofyear  mese  giorno  codice_oss  gradi_giorno_yhat  \\\n",
       "0             1     1       1          11          14.849695   \n",
       "1             1     1       1          13          14.262341   \n",
       "2             1     1       1          14          16.307430   \n",
       "3             1     1       1          15          13.618532   \n",
       "4             1     1       1          16          11.077590   \n",
       "...         ...   ...     ...         ...                ...   \n",
       "6583        366    12      31          25           8.839712   \n",
       "6584        366    12      31          26           8.243516   \n",
       "6585        366    12      31          27          12.737714   \n",
       "6586        366    12      31          28           5.406048   \n",
       "6587        366    12      31          29           6.929239   \n",
       "\n",
       "      gradi_giorno_T_oss      T_oss       std        var       yhat  \\\n",
       "0              15.487500   2.512500  2.746581   7.543705   3.150305   \n",
       "1              15.262500   2.737500  2.591916   6.718030   3.737659   \n",
       "2              17.275000   0.725000  2.819506   7.949612   1.692570   \n",
       "3              13.962500   4.037500  2.676694   7.164693   4.381468   \n",
       "4              10.725000   7.275000  3.039290   9.237281   6.922410   \n",
       "...                  ...        ...       ...        ...        ...   \n",
       "6583           10.166667   7.833333  2.986321   8.918112   9.160288   \n",
       "6584            8.875000   9.125000  3.145037   9.891260   9.756484   \n",
       "6585           14.141667   3.858333  3.438749  11.824998   5.262286   \n",
       "6586            6.541667  11.458333  2.631762   6.926171  12.593952   \n",
       "6587            9.041667   8.958333  2.762812   7.633129  11.070761   \n",
       "\n",
       "      percentile_10_yhat  percentile_90_yhat  percentile_10_T_oss  \\\n",
       "0              -0.370811            6.671421            -1.008616   \n",
       "1               0.414823            7.060496            -0.585337   \n",
       "2              -1.922036            5.307176            -2.889606   \n",
       "3               0.949946            7.812990             0.605978   \n",
       "4               3.026041           10.818780             3.378631   \n",
       "...                  ...                 ...                  ...   \n",
       "6583            5.331825           12.988752             4.004870   \n",
       "6584            5.724546           13.788422             5.093062   \n",
       "6585            0.853810            9.670763            -0.550143   \n",
       "6586            9.220033           15.967870             8.084415   \n",
       "6587            7.528836           14.612686             5.416409   \n",
       "\n",
       "      percentile_90_T_oss  c_i_95_T_oss_l  c_i_95_T_oss_h  c_i_95_yhat_l  \\\n",
       "0                6.033616        2.209186        2.815814       2.846990   \n",
       "1                6.060337        2.451266        3.023734       3.451425   \n",
       "2                4.339606        0.413632        1.036368       1.381202   \n",
       "3                7.469022        3.741903        4.333097       4.085872   \n",
       "4               11.171369        6.939361        7.610639       6.586771   \n",
       "...                   ...             ...             ...            ...   \n",
       "6583            11.661797        7.503544        8.163123       8.830499   \n",
       "6584            13.156938        8.777683        9.472317       9.409167   \n",
       "6585             8.266810        3.478580        4.238086       4.882533   \n",
       "6586            14.832252       11.167699       11.748968      12.303317   \n",
       "6587            12.500258        8.653226        9.263440      10.765654   \n",
       "\n",
       "      c_i_95_yhat_h  \n",
       "0          3.453619  \n",
       "1          4.023894  \n",
       "2          2.003938  \n",
       "3          4.677065  \n",
       "4          7.258050  \n",
       "...             ...  \n",
       "6583       9.490078  \n",
       "6584      10.103802  \n",
       "6585       5.642040  \n",
       "6586      12.884586  \n",
       "6587      11.375868  \n",
       "\n",
       "[6588 rows x 18 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### FILE pre-centralizzazione epson\n",
    "old = pd.read_csv('s3://zus-prod-s3/./mean_d_oss/20000101_20201231_20210510074316/mean_d_oss.csv')\n",
    "old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>mese</th>\n",
       "      <th>giorno</th>\n",
       "      <th>osservatorio</th>\n",
       "      <th>T_mean_m</th>\n",
       "      <th>T_min_abs</th>\n",
       "      <th>T_max_abs</th>\n",
       "      <th>gradi_giorno_yhat_mean</th>\n",
       "      <th>gradi_giorno_T_mean</th>\n",
       "      <th>std</th>\n",
       "      <th>var</th>\n",
       "      <th>yhat_mean</th>\n",
       "      <th>percentile_mean_10_T_norm</th>\n",
       "      <th>percentile_mean_90_T_norm</th>\n",
       "      <th>percentile_mean_10_yhat</th>\n",
       "      <th>percentile_mean_90_yhat</th>\n",
       "      <th>c_i_95_T_mean_m_l</th>\n",
       "      <th>c_i_95_T_mean_m_h</th>\n",
       "      <th>c_i_95_yhat_mean_l</th>\n",
       "      <th>c_i_95_yhat_mean_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.837026</td>\n",
       "      <td>14.312500</td>\n",
       "      <td>2.446740</td>\n",
       "      <td>5.986536</td>\n",
       "      <td>4.162974</td>\n",
       "      <td>0.550779</td>\n",
       "      <td>6.824221</td>\n",
       "      <td>1.026253</td>\n",
       "      <td>7.299695</td>\n",
       "      <td>3.274760</td>\n",
       "      <td>4.100240</td>\n",
       "      <td>3.750234</td>\n",
       "      <td>4.575714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.694006</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>2.478822</td>\n",
       "      <td>6.144558</td>\n",
       "      <td>4.305994</td>\n",
       "      <td>0.072150</td>\n",
       "      <td>6.427850</td>\n",
       "      <td>1.128144</td>\n",
       "      <td>7.483843</td>\n",
       "      <td>2.831848</td>\n",
       "      <td>3.668152</td>\n",
       "      <td>3.887841</td>\n",
       "      <td>4.724146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.312500</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.184100</td>\n",
       "      <td>15.687500</td>\n",
       "      <td>2.671472</td>\n",
       "      <td>7.136763</td>\n",
       "      <td>2.815900</td>\n",
       "      <td>-1.112327</td>\n",
       "      <td>5.737327</td>\n",
       "      <td>-0.608927</td>\n",
       "      <td>6.240727</td>\n",
       "      <td>1.861850</td>\n",
       "      <td>2.763150</td>\n",
       "      <td>2.365250</td>\n",
       "      <td>3.266551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.875000</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.074372</td>\n",
       "      <td>14.125000</td>\n",
       "      <td>2.604532</td>\n",
       "      <td>6.783588</td>\n",
       "      <td>4.925628</td>\n",
       "      <td>0.535990</td>\n",
       "      <td>7.214010</td>\n",
       "      <td>1.586618</td>\n",
       "      <td>8.264638</td>\n",
       "      <td>3.435642</td>\n",
       "      <td>4.314358</td>\n",
       "      <td>4.486270</td>\n",
       "      <td>5.364986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.875000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.702884</td>\n",
       "      <td>11.125000</td>\n",
       "      <td>2.779399</td>\n",
       "      <td>7.725057</td>\n",
       "      <td>7.297116</td>\n",
       "      <td>3.311811</td>\n",
       "      <td>10.438189</td>\n",
       "      <td>3.733927</td>\n",
       "      <td>10.860305</td>\n",
       "      <td>6.406143</td>\n",
       "      <td>7.343857</td>\n",
       "      <td>6.828260</td>\n",
       "      <td>7.765973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6583</th>\n",
       "      <td>366</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.717160</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>2.693736</td>\n",
       "      <td>7.256216</td>\n",
       "      <td>9.282840</td>\n",
       "      <td>4.046630</td>\n",
       "      <td>10.953370</td>\n",
       "      <td>5.829470</td>\n",
       "      <td>12.736210</td>\n",
       "      <td>7.045594</td>\n",
       "      <td>7.954406</td>\n",
       "      <td>8.828433</td>\n",
       "      <td>9.737246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6584</th>\n",
       "      <td>366</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.777778</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.000788</td>\n",
       "      <td>9.222222</td>\n",
       "      <td>2.743894</td>\n",
       "      <td>7.528954</td>\n",
       "      <td>9.999212</td>\n",
       "      <td>5.260106</td>\n",
       "      <td>12.295450</td>\n",
       "      <td>6.481540</td>\n",
       "      <td>13.516884</td>\n",
       "      <td>8.314910</td>\n",
       "      <td>9.240645</td>\n",
       "      <td>9.536344</td>\n",
       "      <td>10.462079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6585</th>\n",
       "      <td>366</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.722222</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.193074</td>\n",
       "      <td>15.277778</td>\n",
       "      <td>3.466396</td>\n",
       "      <td>12.015903</td>\n",
       "      <td>4.806926</td>\n",
       "      <td>-1.721698</td>\n",
       "      <td>7.166142</td>\n",
       "      <td>0.363006</td>\n",
       "      <td>9.250846</td>\n",
       "      <td>2.137476</td>\n",
       "      <td>3.306968</td>\n",
       "      <td>4.222180</td>\n",
       "      <td>5.391672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6586</th>\n",
       "      <td>366</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.801564</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>2.697985</td>\n",
       "      <td>7.279125</td>\n",
       "      <td>12.198436</td>\n",
       "      <td>7.041183</td>\n",
       "      <td>13.958817</td>\n",
       "      <td>8.739619</td>\n",
       "      <td>15.657253</td>\n",
       "      <td>10.044877</td>\n",
       "      <td>10.955123</td>\n",
       "      <td>11.743313</td>\n",
       "      <td>12.653559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6587</th>\n",
       "      <td>366</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.388889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.448623</td>\n",
       "      <td>8.611111</td>\n",
       "      <td>2.514913</td>\n",
       "      <td>6.324788</td>\n",
       "      <td>10.551377</td>\n",
       "      <td>6.164770</td>\n",
       "      <td>12.613007</td>\n",
       "      <td>7.327259</td>\n",
       "      <td>13.775496</td>\n",
       "      <td>8.964648</td>\n",
       "      <td>9.813129</td>\n",
       "      <td>10.127137</td>\n",
       "      <td>10.975618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6588 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dayofyear  mese  giorno  osservatorio   T_mean_m  T_min_abs  T_max_abs  \\\n",
       "0             1     1       1          11.0   3.687500       -5.0       12.0   \n",
       "1             1     1       1          13.0   3.250000       -3.0       12.0   \n",
       "2             1     1       1          14.0   2.312500       -6.0       14.0   \n",
       "3             1     1       1          15.0   3.875000       -5.0       12.0   \n",
       "4             1     1       1          16.0   6.875000       -1.0       16.0   \n",
       "...         ...   ...     ...           ...        ...        ...        ...   \n",
       "6583        366    12      31          25.0   7.500000       -2.0       15.0   \n",
       "6584        366    12      31          26.0   8.777778       -2.0       16.0   \n",
       "6585        366    12      31          27.0   2.722222       -7.0       11.0   \n",
       "6586        366    12      31          28.0  10.500000        0.0       17.0   \n",
       "6587        366    12      31          29.0   9.388889        0.0       18.0   \n",
       "\n",
       "      gradi_giorno_yhat_mean  gradi_giorno_T_mean       std        var  \\\n",
       "0                  13.837026            14.312500  2.446740   5.986536   \n",
       "1                  13.694006            14.750000  2.478822   6.144558   \n",
       "2                  15.184100            15.687500  2.671472   7.136763   \n",
       "3                  13.074372            14.125000  2.604532   6.783588   \n",
       "4                  10.702884            11.125000  2.779399   7.725057   \n",
       "...                      ...                  ...       ...        ...   \n",
       "6583                8.717160            10.500000  2.693736   7.256216   \n",
       "6584                8.000788             9.222222  2.743894   7.528954   \n",
       "6585               13.193074            15.277778  3.466396  12.015903   \n",
       "6586                5.801564             7.500000  2.697985   7.279125   \n",
       "6587                7.448623             8.611111  2.514913   6.324788   \n",
       "\n",
       "      yhat_mean  percentile_mean_10_T_norm  percentile_mean_90_T_norm  \\\n",
       "0      4.162974                   0.550779                   6.824221   \n",
       "1      4.305994                   0.072150                   6.427850   \n",
       "2      2.815900                  -1.112327                   5.737327   \n",
       "3      4.925628                   0.535990                   7.214010   \n",
       "4      7.297116                   3.311811                  10.438189   \n",
       "...         ...                        ...                        ...   \n",
       "6583   9.282840                   4.046630                  10.953370   \n",
       "6584   9.999212                   5.260106                  12.295450   \n",
       "6585   4.806926                  -1.721698                   7.166142   \n",
       "6586  12.198436                   7.041183                  13.958817   \n",
       "6587  10.551377                   6.164770                  12.613007   \n",
       "\n",
       "      percentile_mean_10_yhat  percentile_mean_90_yhat  c_i_95_T_mean_m_l  \\\n",
       "0                    1.026253                 7.299695           3.274760   \n",
       "1                    1.128144                 7.483843           2.831848   \n",
       "2                   -0.608927                 6.240727           1.861850   \n",
       "3                    1.586618                 8.264638           3.435642   \n",
       "4                    3.733927                10.860305           6.406143   \n",
       "...                       ...                      ...                ...   \n",
       "6583                 5.829470                12.736210           7.045594   \n",
       "6584                 6.481540                13.516884           8.314910   \n",
       "6585                 0.363006                 9.250846           2.137476   \n",
       "6586                 8.739619                15.657253          10.044877   \n",
       "6587                 7.327259                13.775496           8.964648   \n",
       "\n",
       "      c_i_95_T_mean_m_h  c_i_95_yhat_mean_l  c_i_95_yhat_mean_h  \n",
       "0              4.100240            3.750234            4.575714  \n",
       "1              3.668152            3.887841            4.724146  \n",
       "2              2.763150            2.365250            3.266551  \n",
       "3              4.314358            4.486270            5.364986  \n",
       "4              7.343857            6.828260            7.765973  \n",
       "...                 ...                 ...                 ...  \n",
       "6583           7.954406            8.828433            9.737246  \n",
       "6584           9.240645            9.536344           10.462079  \n",
       "6585           3.306968            4.222180            5.391672  \n",
       "6586          10.955123           11.743313           12.653559  \n",
       "6587           9.813129           10.127137           10.975618  \n",
       "\n",
       "[6588 rows x 20 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Filo post-centralizzazione epson\n",
    "new = pd.read_csv('s3://zus-prod-s3/epson_centralizzato/mean_d_oss/20000101_20201231_20210510144835/mean_d_oss.csv')\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# path_to_output = 'preprocessato/utente/temperatura_norm/zeus/'\n",
    "# SENZA######################\n",
    "df = pd.read_csv('s3://zus-prod-s3/./mean_d_oss/best/mean_d_oss_20000101_20201231.csv')\n",
    "df#[(df['mese']==1) & (df['provincia']==1)].iloc[0:5]# & (df['giorno']==1)]\n",
    "# df.to_csv('gg_prov_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# path_to_output = 'preprocessato/utente/temperatura_norm/zeus/'\n",
    "# CON ######################\n",
    "df = pd.read_csv('s3://zus-prod-s3/preprocessato/utente/temperatura_norm/zeus/mean_d_oss/best/mean_d_oss_20000101_20201231.csv')\n",
    "df#[(df['mese']==1) & (df['provincia']==1)].iloc[0:5]# & (df['giorno']==1)]\n",
    "# df.to_csv('gg_prov_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('s3://zus-prod-s3/preprocessato/aleedo/temperatura_norm/zeus/mean_d_prov/best/mean_d_prov_20000101_20201231.csv')\n",
    "df[(df['dayofyear']>=93) & (df['dayofyear']<=96) & (df['provincia']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# path_to_output = 'preprocessato/utente/temperatura_norm/zeus/'\n",
    "df = pd.read_csv('s3://zus-prod-s3/preprocessato/utente/temperatura_norm/zeus/mean_d_prov/best/mean_d_prov_20000101_20201231.csv')\n",
    "df[(df['monthday']==\"01-01\")]\n",
    "# df.to_csv('gg_prov_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('s3://zus-prod-s3/preprocessato/utente/temperatura_norm/zeus/mean_d_oss/best/mean_d_oss_20000101_20201231.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loro = pd.read_csv('s3://zus-prod-s3/preprocessato/zeu_user/temperatura_norm/zeus/min_d_prov/best/min_d_prov_20090101_20201231.csv')\n",
    "loro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_prod = pd.read_csv('s3://zus-prod-s3/output/sistema/modello_industriali_diretti/zeus/logs/20200101_20201231_20210401114002/cabine_temperature_incomplete.csv')\n",
    "df_prod.drop_duplicates(subset=['year','CABINE_TEMPERATURE_INCOMPLETE'],inplace=True)\n",
    "df_prod.drop('MESE_ANNO',axis=1,inplace=True)\n",
    "df_prod['year'] = df_prod.apply(lambda x: [2015,2016,2017,2018,2019] if np.isnan(x['year']) else x['year'],axis=1)\n",
    "df_prod.explode('year').iloc[0:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = pd.read_csv('s3://zus-prod-s3/preprocessato/utente/temperatura_norm/zeus/mean_d_prov/best/mean_d_prov_20000101_20201231.csv')\n",
    "df_old[df_old['monthday']==\"01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = pd.read_csv('df_con_92.csv')\n",
    "# old\n",
    "old['date'] = pd.to_datetime(old['date'])\n",
    "max(old['date'])\n",
    "# old[(old['date'].dt.month==9) & (old['date'].dt.day==30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>CAPOLUOGO</th>\n",
       "      <th>PROVINCIA</th>\n",
       "      <th>CIELO</th>\n",
       "      <th>COD_ISTAT</th>\n",
       "      <th>FENOMENO</th>\n",
       "      <th>DATA</th>\n",
       "      <th>DATA_VAL</th>\n",
       "      <th>TIPO</th>\n",
       "      <th>LATITUDINE</th>\n",
       "      <th>LONGITUDINE</th>\n",
       "      <th>TEMPERATURA_MAX</th>\n",
       "      <th>TEMPERATURA_MIN</th>\n",
       "      <th>UDM</th>\n",
       "      <th>QUOTA</th>\n",
       "      <th>REGIONE</th>\n",
       "      <th>DATA_AGGIORNAMENTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>TORINO</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-12-02</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>45.06</td>\n",
       "      <td>7.68</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>°C</td>\n",
       "      <td>239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-05 13:44:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>VERCELLI</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-12-02</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>45.32</td>\n",
       "      <td>8.42</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>°C</td>\n",
       "      <td>130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-05 13:44:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NOVARA</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-12-02</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>45.44</td>\n",
       "      <td>8.61</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>°C</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-05 13:44:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CUNEO</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-12-02</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>44.49</td>\n",
       "      <td>7.54</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>°C</td>\n",
       "      <td>534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-05 13:44:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ASTI</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-12-02</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>44.89</td>\n",
       "      <td>8.20</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>°C</td>\n",
       "      <td>123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-05 13:44:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3157</th>\n",
       "      <td>NaN</td>\n",
       "      <td>VIBO VALENTIA</td>\n",
       "      <td>102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>38.67</td>\n",
       "      <td>16.10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>°C</td>\n",
       "      <td>476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-05 13:44:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3158</th>\n",
       "      <td>NaN</td>\n",
       "      <td>VERBANIA</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>45.92</td>\n",
       "      <td>8.54</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>°C</td>\n",
       "      <td>197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-05 13:44:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MONZA</td>\n",
       "      <td>108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>45.58</td>\n",
       "      <td>9.27</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>°C</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-05 13:44:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160</th>\n",
       "      <td>NaN</td>\n",
       "      <td>FERMO</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>43.16</td>\n",
       "      <td>13.71</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>°C</td>\n",
       "      <td>319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-05 13:44:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BARLETTA</td>\n",
       "      <td>110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>41.31</td>\n",
       "      <td>16.27</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>°C</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-05 13:44:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3162 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AREA      CAPOLUOGO  PROVINCIA  CIELO  COD_ISTAT  FENOMENO        DATA  \\\n",
       "0      NaN         TORINO          1    NaN       1272       NaN  2020-12-02   \n",
       "1      NaN       VERCELLI          2    NaN       2158       NaN  2020-12-02   \n",
       "2      NaN         NOVARA          3    NaN       3106       NaN  2020-12-02   \n",
       "3      NaN          CUNEO          4    NaN       4078       NaN  2020-12-02   \n",
       "4      NaN           ASTI          5    NaN       5005       NaN  2020-12-02   \n",
       "...    ...            ...        ...    ...        ...       ...         ...   \n",
       "3157   NaN  VIBO VALENTIA        102    NaN     102047       NaN  2021-01-01   \n",
       "3158   NaN       VERBANIA        103    NaN     103072       NaN  2021-01-01   \n",
       "3159   NaN          MONZA        108    NaN     108033       NaN  2021-01-01   \n",
       "3160   NaN          FERMO        109    NaN     109006       NaN  2021-01-01   \n",
       "3161   NaN       BARLETTA        110    NaN     110002       NaN  2021-01-01   \n",
       "\n",
       "        DATA_VAL  TIPO  LATITUDINE  LONGITUDINE  TEMPERATURA_MAX  \\\n",
       "0     2020-12-01     1       45.06         7.68              5.0   \n",
       "1     2020-12-01     1       45.32         8.42              6.0   \n",
       "2     2020-12-01     1       45.44         8.61              6.0   \n",
       "3     2020-12-01     1       44.49         7.54              4.0   \n",
       "4     2020-12-01     1       44.89         8.20              6.0   \n",
       "...          ...   ...         ...          ...              ...   \n",
       "3157  2020-12-31     1       38.67        16.10             10.0   \n",
       "3158  2020-12-31     1       45.92         8.54              5.0   \n",
       "3159  2020-12-31     1       45.58         9.27              6.0   \n",
       "3160  2020-12-31     1       43.16        13.71              8.0   \n",
       "3161  2020-12-31     1       41.31        16.27             12.0   \n",
       "\n",
       "      TEMPERATURA_MIN UDM  QUOTA  REGIONE   DATA_AGGIORNAMENTO  \n",
       "0                 1.0  °C    239      NaN  2021-05-05 13:44:19  \n",
       "1                 1.0  °C    130      NaN  2021-05-05 13:44:19  \n",
       "2                 1.0  °C    162      NaN  2021-05-05 13:44:19  \n",
       "3                 0.0  °C    534      NaN  2021-05-05 13:44:19  \n",
       "4                 1.0  °C    123      NaN  2021-05-05 13:44:19  \n",
       "...               ...  ..    ...      ...                  ...  \n",
       "3157              5.0  °C    476      NaN  2021-05-05 13:44:19  \n",
       "3158              2.0  °C    197      NaN  2021-05-05 13:44:19  \n",
       "3159              1.0  °C    162      NaN  2021-05-05 13:44:19  \n",
       "3160              2.0  °C    319      NaN  2021-05-05 13:44:19  \n",
       "3161              5.0  °C     15      NaN  2021-05-05 13:44:19  \n",
       "\n",
       "[3162 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epson = pd.read_csv('s3://zus-prod-s3/preprocessato/sistema/temperatura/epson/temperatura/202012/epson_best.csv')\n",
    "epson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_harmonics(np.array([1,1,1,2,2,2,2,2,7]),6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_harmonics(np.array([2,2,2,2,2,1,1,1,7]),6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.array([1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame({'temp':[ 2.3,  2.25, 2.5,  3.35, 4.,   3.6,\n",
    "  4.,   3.05, 3.2,  4.35, 3.9,  4.5,\n",
    "  2.65, 2.75, 2.2,  1.4,  1.75, 2.6,\n",
    "  3.85, 3.55, 3.25, 3.7,  2.7,  2.6,\n",
    "  3.1,  2.5,  3.,   4.2,  2.85, 2.3,\n",
    "  2.65, 3.35, 3.05, 3.3,  3.,   2.2,\n",
    "  3.5,  2.85, 2.85, 4.3,  3.55, 3.1,\n",
    "  2.95, 3.35, 3.55, 4.6,  4.75, 5.1,\n",
    "  4.1,  5.15, 5.55, 4.95, 5.45, 6.25,\n",
    "  6.15, 6.8,  6.7,  7.5,  5.8, 12.25,\n",
    "  7.55, 9.3,  7.95, 7.9,  6.45, 7.25,\n",
    "  6.55, 7.05, 7.6,  7.1,  8.85, 8.6 ,\n",
    "  9.4,  9.05, 9.65, 9.9,  9.8, 10.65,\n",
    " 10.7,  8.85, 9.05, 9.6, 10.25, 9.6 ,\n",
    "  9.35, 9.7, 10.3, 10.8, 12.05,11.6 ,\n",
    " 12.9, 11.5, 12.3, 12.15,10.8, 11.7 ,\n",
    " 12.55,13.25,12.05,12.95,12.95,12.15,\n",
    " 13.15,13.75,14.,  13.3, 13.5, 13.05,\n",
    " 12.9, 12.2, 13.4, 14.4, 15.6, 15.4 ,\n",
    " 15.85,15.85,15.45,14.35,14.65,14.8 ,\n",
    " 13.7, 15.1, 14.95,15.85,15.45,15.5 ,\n",
    " 15.35,16.85,17.25,17.45,17.1, 18.25,\n",
    " 18.15,16.8, 16.95,14.95,16.1, 17.5 ,\n",
    " 17.,  17.35,17.45,17.55,18.6, 19.8 ,\n",
    " 20.05,18.95,18.05,18.3, 17.65,18.3 ,\n",
    " 18.05,16.95,17.22222222, 18.8, 19.7, 19.95,\n",
    " 20.1, 20.,  19.85,20.45,20.2, 20.6 ,\n",
    " 21.65,21.2, 21.05,21.05,20.55,20.95,\n",
    " 20.7, 21.65,22.,  21.3, 22.1, 22.2 ,\n",
    " 22.2, 22.6, 22.8, 23.1, 23.2, 23.6 ,\n",
    " 22.45,24.1, 23.3, 22.85,23.2, 23.2 ,\n",
    " 24.05,23.35,22.85,22.85,22.75,23.  ,\n",
    " 23.9, 23.75,23.05,23.8, 24.7, 24.45,\n",
    " 23.05,23.65,23.45,23.9, 23.9, 23.7 ,\n",
    " 23.1, 23.15,23.6, 23.65,24.3, 24.3 ,\n",
    " 22.8, 23.35,23.95,23.,  23.3, 22.8 ,\n",
    " 23.8, 23.75,23.7, 23.6, 22.6, 21.85,\n",
    " 22.6, 23.15,22.65,22.6, 21.45,21.1 ,\n",
    " 21.7, 22.85,23.35,22.9, 23.05,23.15,\n",
    " 23.4, 22.05,21.75,21.65,21.5, 21.95,\n",
    " 21.95,21.65,21.25,20.75,20.5, 21.35,\n",
    " 21.1, 20.75,20.55,20.85,20.1, 20.85,\n",
    " 20.85,20.6, 20.6, 19.45,19.05,18.45,\n",
    " 18.2, 18.65,18.8, 17.5, 17.65,18.05,\n",
    " 18.2, 18.45,17.85,17.15,17.25,17.1 ,\n",
    " 16.95,17.05,16.65,16.85,17.6, 17.5 ,\n",
    " 16.1, 16.1, 16.25,17.05,15.85,15.4 ,\n",
    " 15.5, 14.65,14.95,14.75,14.6, 13.3 ,\n",
    " 12.45,13.55,12.85,12.3, 12.25,12.45,\n",
    " 12.7, 12.1, 11.75,12.95,12.15,13.2 ,\n",
    " 12.25,11.7, 11.8, 11.7,  9.95,10.7 ,\n",
    " 10.7, 10.7,  9.85,10.9,  9.85,10.3 ,\n",
    " 10.85, 9.25, 9.2,  9.1,  9.45,10.2 ,\n",
    "  9.,   8.8,  8.5,  8.,   6.6,  7.25,\n",
    "  7.25, 7.15, 5.95, 6.1,  6.4,  6.45,\n",
    "  5.55, 5.1,  4.85, 5.65, 5.15, 5.1 ,\n",
    "  5.1,  4.65, 5.05, 5.35, 4.95, 4.8 ,\n",
    "  4.65, 4.15, 4.,   4.4,  4.05, 3.75,\n",
    "  3.15, 2.65, 3.,   2.4,  2.3,  1.65,\n",
    "  1.25, 2.6,  2.35, 3.55, 3.65, 4.2,\n",
    "  1.75, 1.,   1.4,  2.,   1.7,  2.45]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = pd.read_csv('temp_norm_con_92.csv')\n",
    "senza = pd.read_csv('temp_norm_senza_92.csv')\n",
    "# senza\n",
    "con = con[con['provincia']==1]\n",
    "senza = senza[senza['provincia']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycon = con['T_mean_m'].values.ravel()\n",
    "ysenza = senza['T_mean_m'].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_mean_con = fit_harmonics(ycon, 6)\n",
    "yhat_mean_senza = fit_harmonics(ysenza, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_mean_con[92:95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epson_best = pd.read_csv('s3://zus-prod-s3/preprocessato/sistema/temperatura/epson/temperatura/202012/epson_best.csv')\n",
    "epson_best['OSSERVATORIO'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array([ 2.50600773,  2.48847208,  2.47466042,  2.46448031,  2.45784016,\n",
    "        2.45464994,  2.45482175,  2.45827047,  2.46491431,  2.47467532,\n",
    "        2.48747994,  2.5032594 ,  2.52195011,  2.54349408,  2.56783912,\n",
    "        2.59493917,  2.62475443,  2.65725151,  2.69240348,  2.73018991,\n",
    "        2.77059676,  2.81361635,  2.85924711,  2.90749339,  2.95836521,\n",
    "        3.01187784,  3.06805149,  3.12691085,  3.18848457,  3.2528048 ,\n",
    "        3.31990659,  3.38982731,  3.46260602,  3.53828284,  3.61689824,\n",
    "        3.69849242,  3.78310458,  3.87077221,  3.96153046,  4.05541137,\n",
    "        4.15244326,  4.25265004,  4.35605059,  4.46265812,  4.57247964,\n",
    "        4.68551536,  4.80175826,  4.92119355,  5.04379836,  5.16954129,\n",
    "        5.29838218,  5.43027186,  5.56515192,  5.70295468,  5.84360304,\n",
    "        5.98701058,  6.13308158,  6.28171118,  6.43278562,  6.58618247,\n",
    "        6.74177098,  6.89941253,  7.05896103,  7.22026345,  7.38316044,\n",
    "        7.5474869 ,  7.71307269,  7.87974332,  8.04732073,  8.21562407,\n",
    "        8.38447051,  8.55367611,  8.72305665,  8.89242856,  9.06160974,\n",
    "        9.23042049,  9.39868439,  9.56622919,  9.73288761,  9.89849827,\n",
    "       10.06290643, 10.2259648 , 10.38753432, 10.54748479, 10.7056956 ,\n",
    "       10.86205632, 11.0164672 , 11.16883977, 11.31909716, 11.46717455,\n",
    "       11.61301942, 11.75659184, 11.89786454, 12.03682309, 12.17346586,\n",
    "       12.30780394, 12.43986109, 12.56967344, 12.69728926, 12.82276861,\n",
    "       12.94618291, 13.06761445, 13.18715588, 13.30490954, 13.42098688,\n",
    "       13.53550766, 13.64859925, 13.76039582, 13.87103744, 13.98066929,\n",
    "       14.08944068, 14.19750417, 14.30501461, 14.41212819, 14.51900147,\n",
    "       14.62579045, 14.73264957, 14.83973084, 14.94718283, 15.05514987,\n",
    "       15.16377109, 15.27317964, 15.38350186, 15.49485654, 15.60735423,\n",
    "       15.72109652, 15.83617551, 15.95267321, 16.0706611 , 16.19019966,\n",
    "       16.31133808, 16.43411389, 16.5585528 , 16.68466853, 16.81246274,\n",
    "       16.94192496, 17.07303271, 17.2057516 , 17.3400355 , 17.4758268 ,\n",
    "       17.6130567 , 17.75164565, 17.89150367, 18.03253092, 18.17461817,\n",
    "       18.3176474 , 18.4614924 , 18.60601944, 18.7510879 , 18.89655105,\n",
    "       19.04225671, 19.18804804, 19.3337643 , 19.47924161, 19.6243137 ,\n",
    "       19.76881271, 19.91256993, 20.05541659, 20.19718451, 20.33770692,\n",
    "       20.47681905, 20.61435887, 20.75016765, 20.88409061, 21.01597744,\n",
    "       21.1456828 , 21.27306684, 21.39799557, 21.52034128, 21.63998281,\n",
    "       21.75680589, 21.87070333, 21.9815752 , 22.08932895, 22.19387953,\n",
    "       22.29514934, 22.3930683 , 22.48757369, 22.57861011, 22.66612931,\n",
    "       22.75008998, 22.83045752, 22.90720381, 22.98030686, 23.04975055,\n",
    "       23.11552423, 23.17762237, 23.23604419, 23.29079324, 23.341877  ,\n",
    "       23.38930646, 23.43309572, 23.47326154, 23.50982295, 23.54280085,\n",
    "       23.57221762, 23.59809671, 23.62046232, 23.63933903, 23.65475151,\n",
    "       23.66672419, 23.67528105, 23.68044531, 23.68223928, 23.68068417,\n",
    "       23.67579992, 23.66760514, 23.65611698, 23.64135111, 23.62332169,\n",
    "       23.60204142, 23.57752157, 23.54977202, 23.51880146, 23.48461742,\n",
    "       23.44722649, 23.40663449, 23.36284667, 23.31586789, 23.26570291,\n",
    "       23.21235659, 23.15583418, 23.09614153, 23.03328539, 22.96727368,\n",
    "       22.89811571, 22.82582245, 22.7504068 , 22.67188378, 22.5902708 ,\n",
    "       22.50558782, 22.41785754, 22.32710558, 22.2333606 , 22.13665444,\n",
    "       22.03702217, 21.93450218, 21.82913619, 21.72096926, 21.61004974,\n",
    "       21.49642926, 21.38016256, 21.26130743, 21.13992455, 21.01607727,\n",
    "       20.88983145, 20.76125519, 20.63041858, 20.49739345, 20.36225301,\n",
    "       20.22507158, 20.08592424, 19.94488646, 19.80203379, 19.65744145,\n",
    "       19.51118397, 19.36333486, 19.21396619, 19.06314827, 18.91094928,\n",
    "       18.75743494, 18.60266819, 18.44670887, 18.28961346, 18.1314348 ,\n",
    "       17.97222189, 17.81201964, 17.65086876, 17.48880557, 17.32586192,\n",
    "       17.16206516, 16.99743805, 16.83199882, 16.66576123, 16.49873461,\n",
    "       16.33092405, 16.16233057, 15.99295128, 15.82277971, 15.65180603,\n",
    "       15.4800174 , 15.30739836, 15.13393115, 14.9595962 , 14.78437253,\n",
    "       14.60823822, 14.43117092, 14.25314835, 14.07414879, 13.89415165,\n",
    "       13.71313798, 13.531091  , 13.34799666, 13.16384414, 12.97862639,\n",
    "       12.79234063, 12.6049888 , 12.41657811, 12.22712137, 12.0366375 ,\n",
    "       11.84515183, 11.6526965 , 11.45931073, 11.26504108, 11.06994169,\n",
    "       10.87407443, 10.67750903, 10.48032318, 10.28260248, 10.08444049,\n",
    "        9.88593861,  9.68720594,  9.48835912,  9.28952205,  9.09082564,\n",
    "        8.89240744,  8.69441128,  8.4969868 ,  8.30028902,  8.10447779,\n",
    "        7.90971722,  7.71617512,  7.52402239,  7.33343231,  7.14457994,\n",
    "        6.95764137,  6.77279305,  6.59021106,  6.41007039,  6.23254422,\n",
    "        6.05780318,  5.88601468,  5.71734217,  5.55194448,  5.38997518,\n",
    "        5.2315819 ,  5.07690576,  4.92608082,  4.77923351,  4.63648219,\n",
    "        4.49793668,  4.36369785,  4.23385735,  4.10849724,  3.98768982,\n",
    "        3.8714974 ,  3.75997226,  3.6531565 ,  3.5510821 ,  3.45377097,\n",
    "        3.36123507,  3.27347656,  3.19048807,  3.11225296,  3.03874568,\n",
    "        2.96993215,  2.90577021,  2.84621007,  2.79119491,  2.74066134,\n",
    "        2.6945401 ,  2.65275659,  2.6152316 ,  2.58188193,  2.5526211 ,\n",
    "        2.52736002])\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
