{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main_gg.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main_gg.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "# from scipy import stats\n",
    "from datetime import datetime,timedelta\n",
    "import calendar as c\n",
    "\n",
    "def isdir_s3(bucket, key):\n",
    "    objs = list(bucket.objects.filter(Prefix=key))\n",
    "#     print('I am the master_dir')\n",
    "    return len(objs)\n",
    "\n",
    "def costruzione_file_da_mensile(source, inizio, fine):\n",
    "    bucketname = 'zus-prod-s3'\n",
    "    s3 = boto3.resource('s3')\n",
    "#     source = 'preprocessato/sistema/temperatura/epson/temperatura'\n",
    "    my_bucket = s3.Bucket(bucketname)\n",
    "    annomesi = pd.date_range(inizio, fine,freq='MS').strftime('%Y%m').tolist()\n",
    "    df = pd.DataFrame()\n",
    "    for am in annomesi:\n",
    "        if isdir_s3(my_bucket,source + '/' +str(am))>0:\n",
    "            df = df.append(pd.read_csv('s3://'+bucketname+source+'/'+str(am)+'/epson_best.csv'))\n",
    "    return df\n",
    "\n",
    "def compute_std_var(df_in,finestra_media_mobile_g,col):\n",
    "    df = df_in.copy()\n",
    "#     print(df_in)#.drop('provincia',axis=1).reset_index())\n",
    "    days = int(np.floor(finestra_media_mobile_g/2))\n",
    "    mds = sorted(df.monthday.unique())\n",
    "    min_md = df[df['date']==min(df['date'])]['monthday'].ravel()[0]\n",
    "    max_md = df[df['date']==max(df['date'])]['monthday'].ravel()[0]\n",
    "    df['isleap'] = 0\n",
    "    df['isleap'] = df.apply(lambda x: 1 if c.isleap(x['date'].year) else 0,axis=1)\n",
    "    to_append = pd.DataFrame()\n",
    "    for md in mds:\n",
    "#         print(md)\n",
    "        if md!='02-29':\n",
    "            lista = pd.date_range(datetime.strptime(str(md), \"%m-%d\")-timedelta(days=days), datetime.strptime(str(md), \"%m-%d\")+timedelta(days=days)).strftime(\"%m-%d\").tolist()\n",
    "            var = df[df.monthday.isin(lista)][col].var(ddof=0)\n",
    "#             print(df[df.monthday.isin(lista)])\n",
    "            std = np.sqrt(var)\n",
    "            to_append = to_append.append(pd.DataFrame({col+'_var':[var],col+'_std':[std]},index=[md]))\n",
    "        else:\n",
    "            lista = pd.date_range(datetime.strptime(str('02-22'), \"%m-%d\"), datetime.strptime(str('03-07'), \"%m-%d\")).strftime(\"%m-%d\").tolist()\n",
    "            lista = lista + ['02-29']\n",
    "            var = df[(df.monthday.isin(lista)) & (df.isleap == 1)][col].var(ddof=0)\n",
    "            std = np.sqrt(var)\n",
    "            to_append = to_append.append(pd.DataFrame({col+'_var':[var],col+'_std':[std]},index=[md]))\n",
    "    to_append.reset_index(inplace=True)\n",
    "    to_append.rename(columns={'index':'monthday'},inplace=True)\n",
    "    df = df.merge(to_append,on='monthday',how='left')\n",
    "    return df\n",
    "\n",
    "# def compute_std(df,finestra_media_mobile_g):\n",
    "# #     df['monthday'] = df['date'].dt.month.astype('str').str.pad(2, side='left', fillchar='0') + '-' + df['date'].dt.day.astype('str').str.pad(2, side='left', fillchar='0')\n",
    "#     return df.set_index(['dayofyear', 'year'], append=True).unstack().rolling(window=finestra_media_mobile_g, min_periods=1, center=True).var().stack().groupby('dayofyear')[['T_min_mean', 'T_max_mean','T_mean_m']].agg(lambda x: np.sqrt(np.mean(x)))    \n",
    "\n",
    "# def compute_var(df,finestra_media_mobile_g):\n",
    "#     return df.set_index(['dayofyear', 'year'], append=True).unstack().rolling(window=finestra_media_mobile_g, min_periods=1, center=True).var().stack().groupby('dayofyear')[['T_min_mean', 'T_max_mean','T_mean_m']].agg(lambda x: np.mean(x))\n",
    "\n",
    "def compute_std_month(df,finestra_media_mobile_m):\n",
    "#     print(df)\n",
    "    df = df.set_index(['dayofyear', 'year'], append=True).unstack().rolling(window=finestra_media_mobile_m, min_periods=1, center=True).var().stack().groupby('dayofyear')[['T_min_sum', 'T_max_sum','T_mean_sum']].agg(lambda x: np.sqrt(np.mean(x)))  \n",
    "    df = df.reset_index()\n",
    "    df.rename(columns={'T_min_sum':'std_t_min', 'T_max_sum':'std_t_max','T_mean_sum':'std_t_mean'},inplace=True)\n",
    "    return df\n",
    "    \n",
    "def compute_var_month(df,finestra_media_mobile_m):\n",
    "    df = df.set_index(['dayofyear', 'year'], append=True).unstack().rolling(window=finestra_media_mobile_m, min_periods=1, center=True).var().stack().groupby('dayofyear')[['T_min_sum', 'T_max_sum','T_mean_sum']].agg(lambda x: np.mean(x))  \n",
    "    df = df.reset_index()\n",
    "    df.rename(columns={'T_min_sum':'var_t_min', 'T_max_sum':'var_t_max','T_mean_sum':'var_t_mean'},inplace=True)\n",
    "    return df\n",
    "\n",
    "def compute_std_month_oss(df,finestra_media_mobile_m):\n",
    "    df = df.set_index(['dayofyear', 'year'],append=True).unstack().rolling(window=finestra_media_mobile_m, min_periods=1, center=True).var().stack().groupby('dayofyear')[['T_oss']].agg(lambda x: np.sqrt(np.mean(x)))  \n",
    "    df = df.reset_index()\n",
    "    df.rename(columns={'T_oss':'std_oss'},inplace=True)\n",
    "    return df\n",
    "    \n",
    "def compute_var_month_oss(df,finestra_media_mobile_m):\n",
    "    df = df.set_index(['dayofyear', 'year'],append=True).unstack().rolling(window=finestra_media_mobile_m, min_periods=1, center=True).var().stack().groupby('dayofyear')[['T_oss']].agg(lambda x: np.mean(x))  \n",
    "    df = df.reset_index()\n",
    "    df.rename(columns={'T_oss':'var_oss'},inplace=True)\n",
    "    return df\n",
    "\n",
    "def fit_harmonics(y, n_harmonics):\n",
    "    n = y.shape[0]\n",
    "    X = np.matrix([*[[np.sin(i*k/n*2*np.pi) for i in range(n)] for k in range(n_harmonics)], *[[np.cos(i*k/n*2*np.pi) for i in range(n)] for k in range(n_harmonics)]]).T\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    ols_model = sm.OLS(y, X).fit()\n",
    "    yhat = ols_model.predict(X)\n",
    "    \n",
    "    return yhat\n",
    "\n",
    "# Calcolo percentili\n",
    "def calcolo_percentili(df,column):\n",
    "    if column=='mean':\n",
    "        df['percentile_'+column+'_05_T_norm'] = df['T_'+column+'_m'] - 1.645 * df['std']\n",
    "        df['percentile_'+column+'_95_T_norm'] = df['T_'+column+'_m'] + 1.645 * df['std']\n",
    "        df['percentile_'+column+'_10_T_norm'] = df['T_'+column+'_m'] - 1.282 * df['std']\n",
    "        df['percentile_'+column+'_90_T_norm'] = df['T_'+column+'_m'] + 1.282 * df['std']\n",
    "        df['percentile_'+column+'_25_T_norm'] = df['T_'+column+'_m'] - 0.675 * df['std']\n",
    "        df['percentile_'+column+'_75_T_norm'] = df['T_'+column+'_m'] + 0.675 * df['std']\n",
    "    else:\n",
    "        df['percentile_'+column+'_05_T_norm'] = df['T_'+column+'_mean'] - 1.645 * df['std']\n",
    "        df['percentile_'+column+'_95_T_norm'] = df['T_'+column+'_mean'] + 1.645 * df['std']\n",
    "        df['percentile_'+column+'_10_T_norm'] = df['T_'+column+'_mean'] - 1.282 * df['std']\n",
    "        df['percentile_'+column+'_90_T_norm'] = df['T_'+column+'_mean'] + 1.282 * df['std']\n",
    "        df['percentile_'+column+'_25_T_norm'] = df['T_'+column+'_mean'] - 0.675 * df['std']\n",
    "        df['percentile_'+column+'_75_T_norm'] = df['T_'+column+'_mean'] + 0.675 * df['std']\n",
    "    return df\n",
    "\n",
    "def calcolo_percentili_yhat(df,column):\n",
    "    df['percentile_'+column+'_05_yhat'] = df['yhat_'+column] - 1.645 * df['std']\n",
    "    df['percentile_'+column+'_95_yhat'] = df['yhat_'+column] + 1.645 * df['std']\n",
    "    df['percentile_'+column+'_10_yhat'] = df['yhat_'+column] - 1.282 * df['std']\n",
    "    df['percentile_'+column+'_90_yhat'] = df['yhat_'+column] + 1.282 * df['std']\n",
    "    df['percentile_'+column+'_25_yhat'] = df['yhat_'+column] - 0.675 * df['std']\n",
    "    df['percentile_'+column+'_75_yhat'] = df['yhat_'+column] + 0.675 * df['std']\n",
    "    return df\n",
    "\n",
    "def calcolo_percentili_oss_yhat(df):\n",
    "    df['percentile_05_yhat'] = df['yhat'] - 1.645 * df['std']\n",
    "    df['percentile_95_yhat'] = df['yhat'] + 1.645 * df['std']\n",
    "    df['percentile_10_yhat'] = df['yhat'] - 1.282 * df['std']\n",
    "    df['percentile_90_yhat'] = df['yhat'] + 1.282 * df['std']\n",
    "    df['percentile_25_yhat'] = df['yhat'] - 0.675 * df['std']\n",
    "    df['percentile_75_yhat'] = df['yhat'] + 0.675 * df['std']\n",
    "    return df\n",
    "\n",
    "def calcolo_percentili_oss_T_oss(df):\n",
    "    df['percentile_05_T_oss'] = df['T_oss'] - 1.645 * df['std']\n",
    "    df['percentile_95_T_oss'] = df['T_oss'] + 1.645 * df['std']\n",
    "    df['percentile_10_T_oss'] = df['T_oss'] - 1.282 * df['std']\n",
    "    df['percentile_90_T_oss'] = df['T_oss'] + 1.282 * df['std']\n",
    "    df['percentile_25_T_oss'] = df['T_oss'] - 0.675 * df['std']\n",
    "    df['percentile_75_T_oss'] = df['T_oss'] + 0.675 * df['std']\n",
    "    return df\n",
    "\n",
    "def intervalli_confidenza(df,column):\n",
    "    df['c_i_95_'+column+'_l'] = df[column] - 1.96 * df['std']/np.sqrt(df['n_osservazioni'])\n",
    "    df['c_i_95_'+column+'_h'] = df[column] + 1.96 * df['std']/np.sqrt(df['n_osservazioni'])\n",
    "    return df\n",
    "\n",
    "def lettura_temp_norm(file_t_norm,inizio,fine,finestra_media_mobile_g):\n",
    "#     df = pd.read_csv(file_t_norm)#,encoding='utf-16')\n",
    "    df = costruzione_file_da_mensile(file_t_norm,inizio,fine)\n",
    "    \n",
    "    df = df[['DATA','PROVINCIA','TEMPERATURA_MAX','TEMPERATURA_MIN']]\n",
    "    df.rename(columns={'DATA':'date','PROVINCIA':'provincia','TEMPERATURA_MIN':'temp_min','TEMPERATURA_MAX':'temp_max'},inplace=True)\n",
    "    \n",
    "    df = df[~df['provincia'].isnull()]\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'],format='%d/%m/%Y')\n",
    "    df = df[(df['date']>=inizio) & (df['date']<=fine)]\n",
    "    df['T_mean'] = df[['temp_min', 'temp_max']].mean(axis=1)\n",
    "    df.drop('Desc_Provincia',axis=1,inplace=True)\n",
    "\n",
    "    df = df.assign(\n",
    "        dayofyear=lambda x: (x.date).dt.dayofyear, # + pd.DateOffset(days=92)\n",
    "        year=lambda x: (x.date).dt.year, # + pd.DateOffset(days=92)\n",
    "    )\n",
    "#     df_con = df.assign(\n",
    "#         dayofyear=lambda x: (x.date + pd.DateOffset(days=92)).dt.dayofyear, # + pd.DateOffset(days=92)\n",
    "#         year=lambda x: (x.date + pd.DateOffset(days=92)).dt.year, # + pd.DateOffset(days=92)\n",
    "#     )\n",
    "\n",
    "#     QUA SOTTO METTERE <=9 PER OFFSET=92, SENZA OFFSET METTERE <=12\n",
    "    df['dayofyear'] = df.apply(lambda x: x['dayofyear']+1 if (c.isleap(x['year'])==False and x['date'].month>=3 and x['date'].month<=12) else x['dayofyear'],axis=1)\n",
    "    \n",
    "    df['monthyear'] = (df.date.dt.month).astype('str').str.pad(2, side='left', fillchar='0')+(df.year).astype('str')\n",
    "#     df_con['monthyear'] = (df_con.date.dt.month).astype('str').str.pad(2, side='left', fillchar='0')+(df_con.year).astype('str')\n",
    "    \n",
    "#     df.to_csv('df_senza_92.csv',index=False)\n",
    "#     df_con.to_csv('df_con_92.csv',index=False)\n",
    "#     ciao\n",
    "#     Raggruppo per provincia e monthyear\n",
    "    tmp = (df[['monthyear','date','provincia']].groupby(['monthyear','provincia']).count()).reset_index()\n",
    "    tmp['monthyear'] = tmp['monthyear'].astype('str')\n",
    "    tmp['monthyear'] = tmp['monthyear'].str.slice(stop=2)\n",
    "    tmp.rename(columns={'date':'n_anni','monthyear':'month'},inplace=True)\n",
    "    tmp['n_anni'] = 1\n",
    "    \n",
    "    tmp = tmp.groupby(['month','provincia']).count().reset_index()\n",
    "    \n",
    "    df = df.merge(tmp,on=['provincia'],how='left')\n",
    "    \n",
    "    df['n_osservazioni'] = df['n_anni']*finestra_media_mobile_g\n",
    "\n",
    "    df.drop(['n_anni','month'],axis=1,inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df['monthday'] = df['date'].dt.month.astype('str').str.pad(2, side='left', fillchar='0') + '-' + df['date'].dt.day.astype('str').str.pad(2, side='left', fillchar='0')   \n",
    "    return df\n",
    "\n",
    "def lettura_osservatorio(file_oss,inizio,fine,finestra_media_mobile_g):\n",
    "    df_oss = pd.read_csv(file_oss)\n",
    "    df_oss.rename(columns={'Cd Oss':'codice_oss','T Oss':'T_oss','Data':'date'},inplace=True)\n",
    "    \n",
    "    df_oss['date'] = df_oss['date'].astype('str')\n",
    "    df_oss['date'] = pd.to_datetime(df_oss['date'],format='%Y-%m-%d', exact=False)\n",
    "    df_oss = df_oss[(df_oss['date']>=inizio) & (df_oss['date']<=fine)]\n",
    "    df_oss = df_oss.assign(\n",
    "        dayofyear=lambda x: (x.date).dt.dayofyear, # + pd.DateOffset(days=92)\n",
    "        year=lambda x: (x.date).dt.year, # + pd.DateOffset(days=92)\n",
    "    )\n",
    "    \n",
    "    df_oss['dayofyear'] = df_oss.apply(lambda x: x['dayofyear']+1 if (c.isleap(x['year'])==False and x['date'].month>=3 and x['date'].month<=12) else x['dayofyear'],axis=1)\n",
    "    \n",
    "    df_oss.drop('Oss',axis=1,inplace=True)\n",
    "    df_oss['monthyear'] = (df_oss.date.dt.month).astype('str').str.pad(2, side='left', fillchar='0')+(df_oss.date.dt.year).astype('str')\n",
    "    tmp = (df_oss[['monthyear','date','codice_oss']].groupby(['monthyear','codice_oss']).count()).reset_index()\n",
    "    tmp.rename(columns={'date':'n_anni'},inplace=True) #,'monthyear':'month'\n",
    "    tmp['n_anni'] = 1\n",
    "    tmp['monthyear'] = tmp['monthyear'].astype('str')\n",
    "    tmp['month'] = tmp['monthyear'].str.slice(stop=2)\n",
    "\n",
    "    tmp = tmp.groupby(['month','codice_oss']).count().reset_index()\n",
    "    tmp.drop('monthyear',axis=1,inplace=True)\n",
    "    df_oss['month'] = df_oss['monthyear'].str.slice(stop=2)\n",
    "    df_oss = df_oss.merge(tmp,on=['codice_oss','month'],how='left')\n",
    "    \n",
    "    df_oss['n_osservazioni'] = df_oss['n_anni']*finestra_media_mobile_g\n",
    "    \n",
    "    df_oss.drop(['n_anni'],axis=1,inplace=True)\n",
    "    df_oss['monthday'] = df_oss['date'].dt.month.astype('str').str.pad(2, side='left', fillchar='0') + '-' + df_oss['date'].dt.day.astype('str').str.pad(2, side='left', fillchar='0')\n",
    "    return df_oss\n",
    "\n",
    "def calcolo_temp_norm_gg(file_t_norm,inizio,fine,finestra_media_mobile_g):\n",
    "\n",
    "#     Calcolo temperature normali giornaliere\n",
    "    print(\"Lettura file temperature per provincia.\")\n",
    "    df = lettura_temp_norm(file_t_norm,inizio,fine,finestra_media_mobile_g)\n",
    "    \n",
    "    print(\"Numero province presenti: \",df['provincia'].nunique())\n",
    "    \n",
    "    print(\"Calcolo deviazione standard.\")\n",
    "    df_max = df.groupby('provincia').apply(compute_std_var, finestra_media_mobile_g=finestra_media_mobile_g, col='temp_max')[['provincia','date','temp_max_var','temp_max_std']]\n",
    "    df_min = df.groupby('provincia').apply(compute_std_var, finestra_media_mobile_g=finestra_media_mobile_g, col='temp_min')[['provincia','date','temp_min_var','temp_min_std']]\n",
    "    df_mean = df.groupby('provincia').apply(compute_std_var, finestra_media_mobile_g=finestra_media_mobile_g, col='T_mean')[['provincia','date','T_mean_var','T_mean_std']]\n",
    "\n",
    "    df_max.drop('provincia',axis=1,inplace=True)\n",
    "    df_min.drop('provincia',axis=1,inplace=True)\n",
    "    df_mean.drop('provincia',axis=1,inplace=True)\n",
    "    \n",
    "    df_max.reset_index(inplace=True)\n",
    "    df_min.reset_index(inplace=True)\n",
    "    df_mean.reset_index(inplace=True)\n",
    "    \n",
    "    df = df.merge(df_max, on=['provincia','date'], how='left')\n",
    "    df = df.merge(df_min, on=['provincia','date'], how='left')\n",
    "    df = df.merge(df_mean, on=['provincia','date'], how='left')\n",
    "    \n",
    "    df.rename(columns={'temp_max':'T_max_mean','temp_min':'T_min_mean','T_mean':'T_mean_m'},inplace=True)\n",
    "    \n",
    "#     df.to_csv(\"df_senza_92.csv\",index=False)\n",
    "    \n",
    "    max_min_gg = df.groupby(['dayofyear','provincia']).agg({'T_min_mean':['min'],'T_max_mean':['max']})\n",
    "    max_min_gg.columns = max_min_gg.columns.droplevel(0)\n",
    "    max_min_gg = max_min_gg.reset_index()\n",
    "    max_min_gg.rename(columns={'min':'T_min_abs','max':'T_max_abs'},inplace=True)\n",
    "    \n",
    "    print(\"Calcolo media giornaliera.\")\n",
    "    temp_norm = df.groupby(['dayofyear', 'provincia'])[['T_min_mean', 'T_max_mean','T_mean_m', 'temp_max_std', 'temp_max_var', 'temp_min_std', 'temp_min_var', 'T_mean_std', 'T_mean_var']].mean().unstack().reindex(range(367)).interpolate(method='linear').stack()#.reset_index() #,'T_mean'\n",
    "    \n",
    "    province = temp_norm.reset_index(['provincia']).provincia.unique()\n",
    "    finale = pd.DataFrame()\n",
    "\n",
    "    print(\"Inizio procedura di fit con armoniche di sesto grado.\")\n",
    "#     Fit armoniche di sesto grado per curve T_min, T_max e T_mean\n",
    "    for p in province:\n",
    "        temp_p = temp_norm.query('provincia == {}'.format(p)).reset_index(['provincia','dayofyear'])#.assign(std_mean=lambda x: x['std'], iv_l=lambda x: (x['mean'] - 2*x['std'].rolling(window=15, center=True).mean()), iv_h=lambda x: (x['mean'] + 2*x['std'].rolling(window=15, center=True).mean()))\n",
    "        ###########################\n",
    "#         temp_p = temp_p.merge(tmp,on='')\n",
    "        ###########################\n",
    "        y_min = temp_p['T_min_mean'].values.ravel()\n",
    "        y_max = temp_p['T_max_mean'].values.ravel()\n",
    "        y_mean = temp_p['T_mean_m'].values.ravel()\n",
    "\n",
    "        x = temp_p.index\n",
    "        \n",
    "        yhat_min = fit_harmonics(y_min, 6)\n",
    "        yhat_max = fit_harmonics(y_max, 6)\n",
    "        yhat_mean = fit_harmonics(y_mean, 6)\n",
    "\n",
    "        temp_p['yhat_min'] = yhat_min\n",
    "        temp_p['yhat_max'] = yhat_max\n",
    "        temp_p['yhat_mean'] = yhat_mean\n",
    "        \n",
    "#         if p==1:\n",
    "# #             temp_p.to_csv('temp_p_con_92.csv',index=False)\n",
    "#             print(y_mean)\n",
    "\n",
    "        finale = finale.append(temp_p)\n",
    "        \n",
    "#     Calcolo gradi giorno\n",
    "\n",
    "#################\n",
    "#     ciao\n",
    "#################\n",
    "    print(\"Conversione in gradi giorno.\")\n",
    "    finale['gradi_giorno_yhat_mean'] = 0\n",
    "    finale['gradi_giorno_yhat_mean'] = finale.apply(lambda x: max(0,18-x['yhat_mean']),axis=1)\n",
    "    finale.reset_index(inplace=True)\n",
    "    \n",
    "    finale['gradi_giorno_T_mean'] = 0\n",
    "    finale['gradi_giorno_T_mean'] = finale.apply(lambda x: max(0,18-x['T_mean_m']),axis=1)\n",
    "    finale.reset_index(inplace=True)\n",
    "    \n",
    "    selezione = df[['provincia','n_osservazioni']]\n",
    "    selezione = selezione.groupby('provincia').apply(highest_number)\n",
    "    selezione.drop_duplicates(inplace=True)\n",
    "    finale = finale.merge(selezione,on=['provincia'],how='left')\n",
    "\n",
    "    temp_max = temp_norm[['T_max_mean', 'temp_max_std', 'temp_max_var']].rename(columns={'temp_max_std': 'std', 'temp_max_var': 'var'}).reset_index()\n",
    "    temp_min = temp_norm[['T_min_mean', 'temp_min_std', 'temp_min_var']].rename(columns={'temp_min_std': 'std', 'temp_min_var': 'var'}).reset_index()\n",
    "    temp_mean = temp_norm[['T_mean_m', 'T_mean_std', 'T_mean_var']].rename(columns={'T_mean_std': 'std', 'T_mean_var': 'var'}).reset_index()\n",
    "\n",
    "    temp_max = temp_max.merge(finale[['dayofyear','provincia','yhat_max','n_osservazioni']],on=['dayofyear','provincia'],how='left')\n",
    "    temp_min = temp_min.merge(finale[['dayofyear','provincia','yhat_min','n_osservazioni']],on=['dayofyear','provincia'],how='left')\n",
    "    temp_mean = temp_mean.merge(finale[['dayofyear','provincia','yhat_mean','gradi_giorno_yhat_mean','gradi_giorno_T_mean','n_osservazioni']],on=['dayofyear','provincia'],how='left')\n",
    "\n",
    "    print(\"Calcolo percentili per curve di minimo, massimo e media.\")\n",
    "    temp_max = calcolo_percentili(temp_max,'max')\n",
    "    temp_min = calcolo_percentili(temp_min,'min')\n",
    "    temp_mean = calcolo_percentili(temp_mean,'mean')\n",
    "\n",
    "    temp_max = calcolo_percentili_yhat(temp_max,'max')\n",
    "    temp_min = calcolo_percentili_yhat(temp_min,'min')\n",
    "    temp_mean = calcolo_percentili_yhat(temp_mean,'mean')\n",
    "\n",
    "    print(\"Calcolo intervalli di confidenza per curve di minimo, massimo e media.\")\n",
    "    temp_max = intervalli_confidenza(temp_max,'T_max_mean')\n",
    "    temp_min = intervalli_confidenza(temp_min,'T_min_mean')\n",
    "    temp_mean = intervalli_confidenza(temp_mean,'T_mean_m')\n",
    "    \n",
    "    temp_max = intervalli_confidenza(temp_max,'yhat_max')\n",
    "    temp_min = intervalli_confidenza(temp_min,'yhat_min')\n",
    "    temp_mean = intervalli_confidenza(temp_mean,'yhat_mean')\n",
    "    \n",
    "    prv = pd.DataFrame()\n",
    "    prv['dayofyear'] = range(1,367)\n",
    "    prv['monthday'] = pd.date_range('2020-01-01','2020-12-31').astype('str').str.slice(start=5) #'2019-10-01','2020-09-30' for offset=92!\n",
    "    \n",
    "    temp_max = temp_max.merge(prv,on='dayofyear',how='left')\n",
    "    temp_min = temp_min.merge(prv,on='dayofyear',how='left')\n",
    "    temp_mean = temp_mean.merge(prv,on='dayofyear',how='left')\n",
    "\n",
    "    temp_max['mese'] = temp_max['monthday'].str.slice(stop=2).astype('int')\n",
    "    temp_max['giorno'] = temp_max['monthday'].str.slice(start=-2).astype('int')\n",
    "    \n",
    "    temp_min['mese'] = temp_min['monthday'].str.slice(stop=2).astype('int')\n",
    "    temp_min['giorno'] = temp_min['monthday'].str.slice(start=-2).astype('int')\n",
    "    \n",
    "    temp_mean['mese'] = temp_mean['monthday'].str.slice(stop=2).astype('int')\n",
    "    temp_mean['giorno'] = temp_mean['monthday'].str.slice(start=-2).astype('int')\n",
    "\n",
    "    temp_max = temp_max.merge(max_min_gg,on=['dayofyear','provincia'],how='left')\n",
    "    temp_min = temp_min.merge(max_min_gg,on=['dayofyear','provincia'],how='left')\n",
    "    temp_mean = temp_mean.merge(max_min_gg,on=['dayofyear','provincia'],how='left')\n",
    "\n",
    "    temp_max = temp_max[['dayofyear','mese','giorno','provincia','T_max_mean','T_min_abs','T_max_abs','std','var','yhat_max','percentile_max_10_T_norm','percentile_max_90_T_norm','percentile_max_10_yhat','percentile_max_90_yhat','c_i_95_T_max_mean_l','c_i_95_T_max_mean_h','c_i_95_yhat_max_l','c_i_95_yhat_max_h']]\n",
    "    temp_min = temp_min[['dayofyear','mese','giorno','provincia','T_min_mean','T_min_abs','T_max_abs','std','var','yhat_min','percentile_min_10_T_norm','percentile_min_90_T_norm','percentile_min_10_yhat','percentile_min_90_yhat','c_i_95_T_min_mean_l','c_i_95_T_min_mean_h','c_i_95_yhat_min_l','c_i_95_yhat_min_h']]\n",
    "    temp_mean = temp_mean[['dayofyear','mese','giorno','provincia','T_mean_m','T_min_abs','T_max_abs','gradi_giorno_yhat_mean','gradi_giorno_T_mean','std','var','yhat_mean','percentile_mean_10_T_norm','percentile_mean_90_T_norm','percentile_mean_10_yhat','percentile_mean_90_yhat','c_i_95_T_mean_m_l','c_i_95_T_mean_m_h','c_i_95_yhat_mean_l','c_i_95_yhat_mean_h']]\n",
    "    \n",
    "#     temp_max.rename(columns={'T_min_abs':'t_min_abs','T_max_abs':'t_max_abs','T_max_mean':'t_mean','yhat_max':'yhat','percentile_max_10_T_norm':'percentile_10_t_mean','percentile_max_90_T_norm':'percentile_90_t_mean','percentile_max_10_yhat':'percentile_10_yhat','percentile_max_90_yhat':'percentile_90_yhat','c_i_95_T_max_mean_l':'c_i_95_t_mean_l','c_i_95_T_max_mean_h':'c_i_95_t_mean_u','c_i_95_yhat_max_l':'c_i_95_yhat_l','c_i_95_yhat_max_h':'c_i_95_yhat_u'},inplace=True)\n",
    "#     temp_min.rename(columns={'T_min_abs':'t_min_abs','T_max_abs':'t_max_abs','T_min_mean':'t_mean','yhat_min':'yhat','percentile_min_10_T_norm':'percentile_10_t_mean','percentile_min_90_T_norm':'percentile_90_t_mean','percentile_min_10_yhat':'percentile_10_yhat','percentile_min_90_yhat':'percentile_90_yhat','c_i_95_T_min_mean_l':'c_i_95_t_mean_l','c_i_95_T_min_mean_h':'c_i_95_t_mean_u','c_i_95_yhat_min_l':'c_i_95_yhat_l','c_i_95_yhat_min_h':'c_i_95_yhat_u'},inplace=True)\n",
    "#     temp_mean.rename(columns={'T_min_abs':'t_min_abs','T_max_abs':'t_max_abs','T_mean_m':'t_mean','yhat_mean':'yhat','percentile_mean_10_T_norm':'percentile_10_t_mean','percentile_mean_90_T_norm':'percentile_90_t_mean','percentile_mean_10_yhat':'percentile_10_yhat','percentile_mean_90_yhat':'percentile_90_yhat','c_i_95_T_mean_m_l':'c_i_95_t_mean_l','c_i_95_T_mean_m_h':'c_i_95_t_mean_u','c_i_95_yhat_mean_l':'c_i_95_yhat_l','c_i_95_yhat_mean_h':'c_i_95_yhat_u'},inplace=True)\n",
    "\n",
    "    return temp_max,temp_min,temp_mean\n",
    "\n",
    "def highest_number(df):\n",
    "    df['n_osservazioni'] = df.n_osservazioni.max()\n",
    "    return df\n",
    "\n",
    "def calcolo_oss_gg(file_oss,inizio,fine,finestra_media_mobile_g):\n",
    "\n",
    "    print(\"Lettura file temperature per osservatorio.\")\n",
    "    df_oss = lettura_osservatorio(file_oss,inizio,fine,finestra_media_mobile_g)\n",
    "    \n",
    "    print(\"Numero osservatori presenti: \",df_oss['codice_oss'].nunique())\n",
    "\n",
    "    df_oss = df_oss.assign(\n",
    "        dayofyear=lambda x: (x.date).dt.dayofyear, # + pd.DateOffset(days=92)\n",
    "        year=lambda x: (x.date).dt.year, # + pd.DateOffset(days=92)\n",
    "    )\n",
    "    print(\"Calcolo deviazione standard.\")\n",
    "    df_oss_std_var = df_oss.groupby('codice_oss').apply(compute_std_var, finestra_media_mobile_g=finestra_media_mobile_g, col='T_oss')[['codice_oss','date','T_oss_var','T_oss_std']]\n",
    "    \n",
    "    df_oss_std_var.drop('codice_oss',axis=1,inplace=True)\n",
    "\n",
    "    df_oss_std_var.reset_index(inplace=True)\n",
    "    df_oss = df_oss.merge(df_oss_std_var,on=['codice_oss','date'],how='left')\n",
    "\n",
    "    print(\"Calcolo media giornaliera.\")\n",
    "    temp_oss = df_oss.groupby(['dayofyear', 'codice_oss'])[['T_oss','T_oss_var','T_oss_std']].mean().unstack().reindex(range(367)).interpolate(method='linear').stack() #,'T_mean'\n",
    "\n",
    "    osservatori = temp_oss.reset_index(['codice_oss']).codice_oss.unique()\n",
    "    finale_oss = pd.DataFrame()\n",
    "\n",
    "    print(\"Inizio procedura di fit con armoniche di sesto grado.\")\n",
    "    for o in osservatori:\n",
    "        temp_o = temp_oss.query('codice_oss == {}'.format(o)).reset_index(['codice_oss'])#.assign(std_mean=lambda x: x['std'], iv_l=lambda x: (x['mean'] - 2*x['std'].rolling(window=15, center=True).mean()), iv_h=lambda x: (x['mean'] + 2*x['std'].rolling(window=15, center=True).mean()))\n",
    "\n",
    "        y = temp_o['T_oss'].values.ravel()\n",
    "        x = temp_o.index\n",
    "        \n",
    "        yhat = fit_harmonics(y, 6)\n",
    "\n",
    "        temp_o['yhat'] = yhat\n",
    "\n",
    "        finale_oss = finale_oss.append(temp_o)\n",
    "        \n",
    "    print(\"Conversione in gradi giorno.\")\n",
    "    finale_oss['gradi_giorno_yhat'] = 0\n",
    "    finale_oss['gradi_giorno_yhat'] = finale_oss.apply(lambda x: max(0,18-x['yhat']),axis=1)\n",
    "    finale_oss.reset_index(inplace=True)#[finale['T_mean_m']>=18]\n",
    "\n",
    "    finale_oss['gradi_giorno_T_oss'] = 0\n",
    "    finale_oss['gradi_giorno_T_oss'] = finale_oss.apply(lambda x: max(0,18-x['T_oss']),axis=1)\n",
    "    finale_oss.reset_index(inplace=True)#[finale['T_mean_m']>=18]\n",
    "    \n",
    "    selezione = df_oss[['codice_oss','n_osservazioni']]\n",
    "    selezione = selezione.groupby('codice_oss').apply(highest_number)\n",
    "    selezione.drop_duplicates(inplace=True)\n",
    "        \n",
    "    finale_oss = finale_oss.merge(selezione,on=['codice_oss'],how='left')\n",
    "\n",
    "    temp_oss = temp_oss.reset_index()\n",
    "    temp_oss.drop_duplicates(inplace=True)\n",
    "    temp_oss = temp_oss.set_index(['dayofyear','codice_oss'])\n",
    "\n",
    "    temp_oss_sv = temp_oss[['T_oss', 'T_oss_std', 'T_oss_var']].rename(columns={'T_oss_std': 'std', 'T_oss_var': 'var'}).reset_index()\n",
    "    temp_oss_sv = temp_oss_sv.merge(finale_oss[['dayofyear','codice_oss','yhat','gradi_giorno_T_oss','gradi_giorno_yhat','n_osservazioni']],on=['dayofyear','codice_oss'],how='left')\n",
    "\n",
    "    temp_oss_sv.drop_duplicates(inplace=True)\n",
    "\n",
    "    print(\"Calcolo percentili per curve di minimo, massimo e media.\")\n",
    "    temp_oss_sv = calcolo_percentili_oss_yhat(temp_oss_sv)\n",
    "    temp_oss_sv = calcolo_percentili_oss_T_oss(temp_oss_sv)\n",
    "    \n",
    "    print(\"Calcolo intervalli di confidenza per curve di minimo, massimo e media.\")\n",
    "    temp_oss_sv_T_oss = intervalli_confidenza(temp_oss_sv,'T_oss')\n",
    "    temp_oss_sv_yhat = intervalli_confidenza(temp_oss_sv,'yhat')\n",
    "    \n",
    "    prv = pd.DataFrame()\n",
    "    prv['dayofyear'] = range(1,367)\n",
    "    prv['monthday'] = pd.date_range('2020-01-01','2020-12-31').astype('str').str.slice(start=5)\n",
    "\n",
    "    temp_oss_sv_yhat = temp_oss_sv_yhat.merge(prv,on='dayofyear',how='left')\n",
    "    \n",
    "    temp_oss_sv_yhat['mese'] = temp_oss_sv_yhat['monthday'].str.slice(stop=2).astype('int')\n",
    "    temp_oss_sv_yhat['giorno'] = temp_oss_sv_yhat['monthday'].str.slice(start=-2).astype('int')\n",
    "    \n",
    "    temp_oss_sv_yhat = temp_oss_sv_yhat[['dayofyear','mese','giorno','codice_oss','gradi_giorno_yhat','gradi_giorno_T_oss','T_oss','std','var','yhat','percentile_10_yhat','percentile_90_yhat','percentile_10_T_oss','percentile_90_T_oss','c_i_95_T_oss_l','c_i_95_T_oss_h','c_i_95_yhat_l','c_i_95_yhat_h']]\n",
    "    \n",
    "    return temp_oss_sv_yhat\n",
    "\n",
    "def main_gg(file_input,inizio,fine,finestra_media_mobile_g,path_to_output):\n",
    "    \n",
    "    print('Funzione dedicata al calcolo delle temperature giornaliere e mensili.')\n",
    "    print('\\n')\n",
    "    \n",
    "    my_bucket = 'zus-prod-s3'\n",
    "    \n",
    "    finestra_media_mobile_g = int(finestra_media_mobile_g)\n",
    "    \n",
    "    inizio_dt = pd.to_datetime(inizio,format=\"%Y-%m-%d\")\n",
    "    fine_dt = pd.to_datetime(fine,format=\"%Y-%m-%d\")\n",
    "    \n",
    "    file_name_out = inizio.replace('-','') + '_' + fine.replace('-','') + '_' + str(datetime.now())[0:-7].replace('-','').replace(' ','').replace(':','')\n",
    "        \n",
    "    df = pd.read_csv('s3://'+ my_bucket +'/'+file_input)#,encoding='utf-16')\n",
    "    if 'Codice Provincia' in df.columns:\n",
    "        print('Calcolo temperatura normale giornaliera con funzioni armoniche di 6^ grado')\n",
    "        temp_max_norm, temp_min_norm, temp_mean_norm = calcolo_temp_norm_gg('s3://'+ my_bucket +'/'+file_input,inizio_dt,fine_dt,finestra_media_mobile_g)\n",
    "#         temp_max_norm.drop('dayofyear',inplace=True,axis=1)\n",
    "#         temp_min_norm.drop('dayofyear',inplace=True,axis=1)\n",
    "#         temp_mean_norm.drop('dayofyear',inplace=True,axis=1)\n",
    "        \n",
    "        temp_max_norm.to_csv('s3://'+ my_bucket +'/'+path_to_output+'max_d_prov/'+file_name_out+'/max_d_prov.csv',index=False)\n",
    "        idrun_max = 's3://'+ my_bucket +'/'+path_to_output+'max_d_prov/'+file_name_out+'/max_d_prov.csv'\n",
    "        metadatati_max = pd.DataFrame(data={'MODELLO':['MAX_D_PROV']*4,'ID_RUN':[idrun_max]*4,'NOME_PARAMETRO':['INIZIO','FINE','FINESTRA_MEDIA_MOBILE_G','PATH_TO_OUTPUT'],'VALORE_PARAMETRO':[inizio,fine,finestra_media_mobile_g,path_to_output]})\n",
    "        metadatati_max.to_csv('s3://'+ my_bucket +'/metadati/sistema/temperatura_norm/zeus/metadati/max_d_prov/'+file_name_out+'/metadati.csv',index=False)\n",
    "        \n",
    "        temp_min_norm.to_csv('s3://'+ my_bucket +'/'+path_to_output+'min_d_prov/'+file_name_out+'/min_d_prov.csv',index=False)\n",
    "        idrun_min = 's3://'+ my_bucket +'/'+path_to_output+'min_d_prov/'+file_name_out+'/min_d_prov.csv'\n",
    "        metadatati_min = pd.DataFrame(data={'MODELLO':['MIN_D_PROV']*4,'ID_RUN':[idrun_min]*4,'NOME_PARAMETRO':['INIZIO','FINE','FINESTRA_MEDIA_MOBILE_G','PATH_TO_OUTPUT'],'VALORE_PARAMETRO':[inizio,fine,finestra_media_mobile_g,path_to_output]})\n",
    "        metadatati_min.to_csv('s3://'+ my_bucket +'/metadati/sistema/temperatura_norm/zeus/metadati/min_d_prov/'+file_name_out+'/metadati.csv',index=False)\n",
    "        \n",
    "        temp_mean_norm.to_csv('s3://'+ my_bucket +'/'+path_to_output+'mean_d_prov/'+file_name_out+'/mean_d_prov.csv',index=False)\n",
    "        idrun_mean = 's3://'+ my_bucket +'/'+path_to_output+'mean_d_prov/'+file_name_out+'/mean_d_prov.csv'\n",
    "        metadatati_mean = pd.DataFrame(data={'MODELLO':['MEAN_D_PROV']*4,'ID_RUN':[idrun_mean]*4,'NOME_PARAMETRO':['INIZIO','FINE','FINESTRA_MEDIA_MOBILE_G','PATH_TO_OUTPUT'],'VALORE_PARAMETRO':[inizio,fine,finestra_media_mobile_g,path_to_output]})\n",
    "        metadatati_mean.to_csv('s3://'+ my_bucket +'/metadati/sistema/temperatura_norm/zeus/metadati/mean_d_prov/'+file_name_out+'/metadati.csv',index=False)\n",
    "#         temp_max_norm.to_csv('prova_gg_max.csv',index=False)\n",
    "#         temp_min_norm.to_csv('prova_gg_min.csv',index=False)\n",
    "#         temp_mean_norm.to_csv('prova_gg_mean.csv',index=False)\n",
    "        print('\\n')\n",
    "    else:\n",
    "        print('Calcolo osservatorio giornaliero con funzioni armoniche di 6^ grado')\n",
    "        temp_oss_sv = calcolo_oss_gg('s3://'+ my_bucket +'/'+file_input,inizio_dt,fine_dt,finestra_media_mobile_g)\n",
    "        #temp_oss_sv.drop(columns='dayofyear',inplace=True,axis=1)\n",
    "        \n",
    "        temp_oss_sv.to_csv('s3://'+ my_bucket +'/'+path_to_output+'mean_d_oss/'+file_name_out+'/mean_d_oss.csv',index=False)\n",
    "        idrun = 's3://'+ my_bucket +'/'+path_to_output+'mean_d_oss/'+file_name_out+'/mean_d_oss.csv'\n",
    "        metadati = pd.DataFrame(data={'MODELLO':['MEAN_D_OSS']*4,'ID_RUN':[idrun]*4,'NOME_PARAMETRO':['INIZIO','FINE','FINESTRA_MEDIA_MOBILE_G','PATH_TO_OUTPUT'],'VALORE_PARAMETRO':[inizio,fine,finestra_media_mobile_g,path_to_output]})\n",
    "        metadati.to_csv('s3://'+ my_bucket +'/metadati/sistema/mean_d_v/zeus/temperatura_norm/zeus/metadati/mean_d_oss/'+file_name_out+'/metadati.csv',index=False)\n",
    "#         temp_oss_sv.to_csv('prova_gg_oss.csv',index=False)\n",
    "        print('\\n')\n",
    "    print(\"Procedura terminata.\")\n",
    "    \n",
    "#     return temp_max_norm, temp_min_norm, temp_mean_norm, temp_oss_sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funzione dedicata al calcolo delle temperature giornaliere e mensili.\n",
      "\n",
      "\n",
      "Calcolo temperatura normale giornaliera con funzioni armoniche di 6^ grado\n",
      "Lettura file temperature per provincia.\n",
      "Numero province presenti:  103\n",
      "Calcolo deviazione standard.\n",
      "Calcolo media giornaliera.\n",
      "Inizio procedura di fit con armoniche di sesto grado.\n",
      "Conversione in gradi giorno.\n",
      "Calcolo percentili per curve di minimo, massimo e media.\n",
      "Calcolo intervalli di confidenza per curve di minimo, massimo e media.\n",
      "\n",
      "\n",
      "Procedura terminata.\n"
     ]
    }
   ],
   "source": [
    "main_gg('preprocessato/sistema/temperatura_norm/zeus/storico/Storico_Temp_2005-2015.csv','2000-01-01','2020-12-31',15,'./')\n",
    "##### NUOVO PATH: 'preprocessato/sistema/temperatura/epson/temperatura'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bucket = 'zus-prod-s3'\n",
    "# filre_input = ''\n",
    "# pd.read_csv('s3://'+ my_bucket +'/'+file_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# path_to_output = 'preprocessato/utente/temperatura_norm/zeus/'\n",
    "# SENZA######################\n",
    "df = pd.read_csv('s3://zus-prod-s3/./mean_d_oss/best/mean_d_oss_20000101_20201231.csv')\n",
    "df#[(df['mese']==1) & (df['provincia']==1)].iloc[0:5]# & (df['giorno']==1)]\n",
    "# df.to_csv('gg_prov_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# path_to_output = 'preprocessato/utente/temperatura_norm/zeus/'\n",
    "# CON ######################\n",
    "df = pd.read_csv('s3://zus-prod-s3/preprocessato/utente/temperatura_norm/zeus/mean_d_oss/best/mean_d_oss_20000101_20201231.csv')\n",
    "df#[(df['mese']==1) & (df['provincia']==1)].iloc[0:5]# & (df['giorno']==1)]\n",
    "# df.to_csv('gg_prov_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('s3://zus-prod-s3/preprocessato/aleedo/temperatura_norm/zeus/mean_d_prov/best/mean_d_prov_20000101_20201231.csv')\n",
    "df[(df['dayofyear']>=93) & (df['dayofyear']<=96) & (df['provincia']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# path_to_output = 'preprocessato/utente/temperatura_norm/zeus/'\n",
    "df = pd.read_csv('s3://zus-prod-s3/preprocessato/utente/temperatura_norm/zeus/mean_d_prov/best/mean_d_prov_20000101_20201231.csv')\n",
    "df[(df['monthday']==\"01-01\")]\n",
    "# df.to_csv('gg_prov_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('s3://zus-prod-s3/preprocessato/utente/temperatura_norm/zeus/mean_d_oss/best/mean_d_oss_20000101_20201231.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loro = pd.read_csv('s3://zus-prod-s3/preprocessato/zeu_user/temperatura_norm/zeus/min_d_prov/best/min_d_prov_20090101_20201231.csv')\n",
    "loro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_prod = pd.read_csv('s3://zus-prod-s3/output/sistema/modello_industriali_diretti/zeus/logs/20200101_20201231_20210401114002/cabine_temperature_incomplete.csv')\n",
    "df_prod.drop_duplicates(subset=['year','CABINE_TEMPERATURE_INCOMPLETE'],inplace=True)\n",
    "df_prod.drop('MESE_ANNO',axis=1,inplace=True)\n",
    "df_prod['year'] = df_prod.apply(lambda x: [2015,2016,2017,2018,2019] if np.isnan(x['year']) else x['year'],axis=1)\n",
    "df_prod.explode('year').iloc[0:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = pd.read_csv('s3://zus-prod-s3/preprocessato/utente/temperatura_norm/zeus/mean_d_prov/best/mean_d_prov_20000101_20201231.csv')\n",
    "df_old[df_old['monthday']==\"01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = pd.read_csv('df_con_92.csv')\n",
    "# old\n",
    "old['date'] = pd.to_datetime(old['date'])\n",
    "max(old['date'])\n",
    "# old[(old['date'].dt.month==9) & (old['date'].dt.day==30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('df_senza_92.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_harmonics(np.array([1,1,1,2,2,2,2,2,7]),6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_harmonics(np.array([2,2,2,2,2,1,1,1,7]),6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.array([1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame({'temp':[ 2.3,  2.25, 2.5,  3.35, 4.,   3.6,\n",
    "  4.,   3.05, 3.2,  4.35, 3.9,  4.5,\n",
    "  2.65, 2.75, 2.2,  1.4,  1.75, 2.6,\n",
    "  3.85, 3.55, 3.25, 3.7,  2.7,  2.6,\n",
    "  3.1,  2.5,  3.,   4.2,  2.85, 2.3,\n",
    "  2.65, 3.35, 3.05, 3.3,  3.,   2.2,\n",
    "  3.5,  2.85, 2.85, 4.3,  3.55, 3.1,\n",
    "  2.95, 3.35, 3.55, 4.6,  4.75, 5.1,\n",
    "  4.1,  5.15, 5.55, 4.95, 5.45, 6.25,\n",
    "  6.15, 6.8,  6.7,  7.5,  5.8, 12.25,\n",
    "  7.55, 9.3,  7.95, 7.9,  6.45, 7.25,\n",
    "  6.55, 7.05, 7.6,  7.1,  8.85, 8.6 ,\n",
    "  9.4,  9.05, 9.65, 9.9,  9.8, 10.65,\n",
    " 10.7,  8.85, 9.05, 9.6, 10.25, 9.6 ,\n",
    "  9.35, 9.7, 10.3, 10.8, 12.05,11.6 ,\n",
    " 12.9, 11.5, 12.3, 12.15,10.8, 11.7 ,\n",
    " 12.55,13.25,12.05,12.95,12.95,12.15,\n",
    " 13.15,13.75,14.,  13.3, 13.5, 13.05,\n",
    " 12.9, 12.2, 13.4, 14.4, 15.6, 15.4 ,\n",
    " 15.85,15.85,15.45,14.35,14.65,14.8 ,\n",
    " 13.7, 15.1, 14.95,15.85,15.45,15.5 ,\n",
    " 15.35,16.85,17.25,17.45,17.1, 18.25,\n",
    " 18.15,16.8, 16.95,14.95,16.1, 17.5 ,\n",
    " 17.,  17.35,17.45,17.55,18.6, 19.8 ,\n",
    " 20.05,18.95,18.05,18.3, 17.65,18.3 ,\n",
    " 18.05,16.95,17.22222222, 18.8, 19.7, 19.95,\n",
    " 20.1, 20.,  19.85,20.45,20.2, 20.6 ,\n",
    " 21.65,21.2, 21.05,21.05,20.55,20.95,\n",
    " 20.7, 21.65,22.,  21.3, 22.1, 22.2 ,\n",
    " 22.2, 22.6, 22.8, 23.1, 23.2, 23.6 ,\n",
    " 22.45,24.1, 23.3, 22.85,23.2, 23.2 ,\n",
    " 24.05,23.35,22.85,22.85,22.75,23.  ,\n",
    " 23.9, 23.75,23.05,23.8, 24.7, 24.45,\n",
    " 23.05,23.65,23.45,23.9, 23.9, 23.7 ,\n",
    " 23.1, 23.15,23.6, 23.65,24.3, 24.3 ,\n",
    " 22.8, 23.35,23.95,23.,  23.3, 22.8 ,\n",
    " 23.8, 23.75,23.7, 23.6, 22.6, 21.85,\n",
    " 22.6, 23.15,22.65,22.6, 21.45,21.1 ,\n",
    " 21.7, 22.85,23.35,22.9, 23.05,23.15,\n",
    " 23.4, 22.05,21.75,21.65,21.5, 21.95,\n",
    " 21.95,21.65,21.25,20.75,20.5, 21.35,\n",
    " 21.1, 20.75,20.55,20.85,20.1, 20.85,\n",
    " 20.85,20.6, 20.6, 19.45,19.05,18.45,\n",
    " 18.2, 18.65,18.8, 17.5, 17.65,18.05,\n",
    " 18.2, 18.45,17.85,17.15,17.25,17.1 ,\n",
    " 16.95,17.05,16.65,16.85,17.6, 17.5 ,\n",
    " 16.1, 16.1, 16.25,17.05,15.85,15.4 ,\n",
    " 15.5, 14.65,14.95,14.75,14.6, 13.3 ,\n",
    " 12.45,13.55,12.85,12.3, 12.25,12.45,\n",
    " 12.7, 12.1, 11.75,12.95,12.15,13.2 ,\n",
    " 12.25,11.7, 11.8, 11.7,  9.95,10.7 ,\n",
    " 10.7, 10.7,  9.85,10.9,  9.85,10.3 ,\n",
    " 10.85, 9.25, 9.2,  9.1,  9.45,10.2 ,\n",
    "  9.,   8.8,  8.5,  8.,   6.6,  7.25,\n",
    "  7.25, 7.15, 5.95, 6.1,  6.4,  6.45,\n",
    "  5.55, 5.1,  4.85, 5.65, 5.15, 5.1 ,\n",
    "  5.1,  4.65, 5.05, 5.35, 4.95, 4.8 ,\n",
    "  4.65, 4.15, 4.,   4.4,  4.05, 3.75,\n",
    "  3.15, 2.65, 3.,   2.4,  2.3,  1.65,\n",
    "  1.25, 2.6,  2.35, 3.55, 3.65, 4.2,\n",
    "  1.75, 1.,   1.4,  2.,   1.7,  2.45]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = pd.read_csv('temp_norm_con_92.csv')\n",
    "senza = pd.read_csv('temp_norm_senza_92.csv')\n",
    "# senza\n",
    "con = con[con['provincia']==1]\n",
    "senza = senza[senza['provincia']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycon = con['T_mean_m'].values.ravel()\n",
    "ysenza = senza['T_mean_m'].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_mean_con = fit_harmonics(ycon, 6)\n",
    "yhat_mean_senza = fit_harmonics(ysenza, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_mean_con[92:95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_mean_senza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array([ 2.50600773,  2.48847208,  2.47466042,  2.46448031,  2.45784016,\n",
    "        2.45464994,  2.45482175,  2.45827047,  2.46491431,  2.47467532,\n",
    "        2.48747994,  2.5032594 ,  2.52195011,  2.54349408,  2.56783912,\n",
    "        2.59493917,  2.62475443,  2.65725151,  2.69240348,  2.73018991,\n",
    "        2.77059676,  2.81361635,  2.85924711,  2.90749339,  2.95836521,\n",
    "        3.01187784,  3.06805149,  3.12691085,  3.18848457,  3.2528048 ,\n",
    "        3.31990659,  3.38982731,  3.46260602,  3.53828284,  3.61689824,\n",
    "        3.69849242,  3.78310458,  3.87077221,  3.96153046,  4.05541137,\n",
    "        4.15244326,  4.25265004,  4.35605059,  4.46265812,  4.57247964,\n",
    "        4.68551536,  4.80175826,  4.92119355,  5.04379836,  5.16954129,\n",
    "        5.29838218,  5.43027186,  5.56515192,  5.70295468,  5.84360304,\n",
    "        5.98701058,  6.13308158,  6.28171118,  6.43278562,  6.58618247,\n",
    "        6.74177098,  6.89941253,  7.05896103,  7.22026345,  7.38316044,\n",
    "        7.5474869 ,  7.71307269,  7.87974332,  8.04732073,  8.21562407,\n",
    "        8.38447051,  8.55367611,  8.72305665,  8.89242856,  9.06160974,\n",
    "        9.23042049,  9.39868439,  9.56622919,  9.73288761,  9.89849827,\n",
    "       10.06290643, 10.2259648 , 10.38753432, 10.54748479, 10.7056956 ,\n",
    "       10.86205632, 11.0164672 , 11.16883977, 11.31909716, 11.46717455,\n",
    "       11.61301942, 11.75659184, 11.89786454, 12.03682309, 12.17346586,\n",
    "       12.30780394, 12.43986109, 12.56967344, 12.69728926, 12.82276861,\n",
    "       12.94618291, 13.06761445, 13.18715588, 13.30490954, 13.42098688,\n",
    "       13.53550766, 13.64859925, 13.76039582, 13.87103744, 13.98066929,\n",
    "       14.08944068, 14.19750417, 14.30501461, 14.41212819, 14.51900147,\n",
    "       14.62579045, 14.73264957, 14.83973084, 14.94718283, 15.05514987,\n",
    "       15.16377109, 15.27317964, 15.38350186, 15.49485654, 15.60735423,\n",
    "       15.72109652, 15.83617551, 15.95267321, 16.0706611 , 16.19019966,\n",
    "       16.31133808, 16.43411389, 16.5585528 , 16.68466853, 16.81246274,\n",
    "       16.94192496, 17.07303271, 17.2057516 , 17.3400355 , 17.4758268 ,\n",
    "       17.6130567 , 17.75164565, 17.89150367, 18.03253092, 18.17461817,\n",
    "       18.3176474 , 18.4614924 , 18.60601944, 18.7510879 , 18.89655105,\n",
    "       19.04225671, 19.18804804, 19.3337643 , 19.47924161, 19.6243137 ,\n",
    "       19.76881271, 19.91256993, 20.05541659, 20.19718451, 20.33770692,\n",
    "       20.47681905, 20.61435887, 20.75016765, 20.88409061, 21.01597744,\n",
    "       21.1456828 , 21.27306684, 21.39799557, 21.52034128, 21.63998281,\n",
    "       21.75680589, 21.87070333, 21.9815752 , 22.08932895, 22.19387953,\n",
    "       22.29514934, 22.3930683 , 22.48757369, 22.57861011, 22.66612931,\n",
    "       22.75008998, 22.83045752, 22.90720381, 22.98030686, 23.04975055,\n",
    "       23.11552423, 23.17762237, 23.23604419, 23.29079324, 23.341877  ,\n",
    "       23.38930646, 23.43309572, 23.47326154, 23.50982295, 23.54280085,\n",
    "       23.57221762, 23.59809671, 23.62046232, 23.63933903, 23.65475151,\n",
    "       23.66672419, 23.67528105, 23.68044531, 23.68223928, 23.68068417,\n",
    "       23.67579992, 23.66760514, 23.65611698, 23.64135111, 23.62332169,\n",
    "       23.60204142, 23.57752157, 23.54977202, 23.51880146, 23.48461742,\n",
    "       23.44722649, 23.40663449, 23.36284667, 23.31586789, 23.26570291,\n",
    "       23.21235659, 23.15583418, 23.09614153, 23.03328539, 22.96727368,\n",
    "       22.89811571, 22.82582245, 22.7504068 , 22.67188378, 22.5902708 ,\n",
    "       22.50558782, 22.41785754, 22.32710558, 22.2333606 , 22.13665444,\n",
    "       22.03702217, 21.93450218, 21.82913619, 21.72096926, 21.61004974,\n",
    "       21.49642926, 21.38016256, 21.26130743, 21.13992455, 21.01607727,\n",
    "       20.88983145, 20.76125519, 20.63041858, 20.49739345, 20.36225301,\n",
    "       20.22507158, 20.08592424, 19.94488646, 19.80203379, 19.65744145,\n",
    "       19.51118397, 19.36333486, 19.21396619, 19.06314827, 18.91094928,\n",
    "       18.75743494, 18.60266819, 18.44670887, 18.28961346, 18.1314348 ,\n",
    "       17.97222189, 17.81201964, 17.65086876, 17.48880557, 17.32586192,\n",
    "       17.16206516, 16.99743805, 16.83199882, 16.66576123, 16.49873461,\n",
    "       16.33092405, 16.16233057, 15.99295128, 15.82277971, 15.65180603,\n",
    "       15.4800174 , 15.30739836, 15.13393115, 14.9595962 , 14.78437253,\n",
    "       14.60823822, 14.43117092, 14.25314835, 14.07414879, 13.89415165,\n",
    "       13.71313798, 13.531091  , 13.34799666, 13.16384414, 12.97862639,\n",
    "       12.79234063, 12.6049888 , 12.41657811, 12.22712137, 12.0366375 ,\n",
    "       11.84515183, 11.6526965 , 11.45931073, 11.26504108, 11.06994169,\n",
    "       10.87407443, 10.67750903, 10.48032318, 10.28260248, 10.08444049,\n",
    "        9.88593861,  9.68720594,  9.48835912,  9.28952205,  9.09082564,\n",
    "        8.89240744,  8.69441128,  8.4969868 ,  8.30028902,  8.10447779,\n",
    "        7.90971722,  7.71617512,  7.52402239,  7.33343231,  7.14457994,\n",
    "        6.95764137,  6.77279305,  6.59021106,  6.41007039,  6.23254422,\n",
    "        6.05780318,  5.88601468,  5.71734217,  5.55194448,  5.38997518,\n",
    "        5.2315819 ,  5.07690576,  4.92608082,  4.77923351,  4.63648219,\n",
    "        4.49793668,  4.36369785,  4.23385735,  4.10849724,  3.98768982,\n",
    "        3.8714974 ,  3.75997226,  3.6531565 ,  3.5510821 ,  3.45377097,\n",
    "        3.36123507,  3.27347656,  3.19048807,  3.11225296,  3.03874568,\n",
    "        2.96993215,  2.90577021,  2.84621007,  2.79119491,  2.74066134,\n",
    "        2.6945401 ,  2.65275659,  2.6152316 ,  2.58188193,  2.5526211 ,\n",
    "        2.52736002])\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
